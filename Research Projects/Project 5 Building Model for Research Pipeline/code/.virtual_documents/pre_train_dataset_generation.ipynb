





import pandas as pd

from rdkit import Chem
from rdkit.Chem import AllChem
from rdkit.Chem import Descriptors
from rdkit.Chem import Draw
from rdkit.Chem.rdMolDescriptors import CalcNumAtomStereoCenters
from rdkit.Chem.rdchem import BondType
from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect

from sklearn.preprocessing import StandardScaler



def PRINT() -> None: print(f"{'-'*80}\nDone\n{'-'*80}")
def PRINTM(M) -> None: print(f"{'-'*80}\n{M}\n{'-'*80}")





import os
import pandas as pd


pt_dataset_path = os.path.join(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\pt_dataset.csv")
pt_dataset = pd.read_csv(pt_dataset_path)

PRINTM('Loaded the dataset successfully')


pt_dataset = pt_dataset[['SMILES']]


PRINTM(f'The shape of the dateset -> {pt_dataset.shape}')


sample_smiles = pt_dataset['SMILES'].head(15)
molecules = [Chem.MolFromSmiles(smile) for smile in sample_smiles]

# Visualize the molecules
img = Draw.MolsToGridImage(molecules, molsPerRow=5, subImgSize=(300, 200))
img





initial_descriptor_names = [
    "NumAtomStereoCenters",
    "NumAminoBonds",
    "MolWt",
    "NumValenceElectrons",
    "TPSA",
    "MolLogP",
    "NumHeteroatoms",
    "NumRotatableBonds",
    "HeavyAtomCount",
    "FractionCSP3",
    "NumAtomStereoCenters",
    "NumAminoBonds"
]


from rdkit import Chem
from rdkit.Chem import AllChem, Descriptors

def generate_descriptors(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is not None:
        initial_descriptors = [
            AllChem.CalcNumAtomStereoCenters(mol),
            AllChem.CalcNumAmideBonds(mol),
            Descriptors.MolWt(mol),
            Descriptors.NumValenceElectrons(mol),
            Descriptors.TPSA(mol),
            Descriptors.MolLogP(mol),
            Descriptors.NumHeteroatoms(mol),
            Descriptors.NumRotatableBonds(mol),
            Descriptors.HeavyAtomCount(mol),
            Descriptors.FractionCSP3(mol)
        ]
        
        all_descriptors = []
        descriptor_names = []
        for name, func in Descriptors.descList:
            all_descriptors.append(func(mol))
            descriptor_names.append(name)
        
        # Ensure we have at least 300 descriptors by padding if necessary
        if len(all_descriptors) < 300:
            all_descriptors.extend([None] * (300 - len(all_descriptors)))
            descriptor_names.extend([None] * (300 - len(descriptor_names)))
        
        # Replace the first 10 descriptors with the initial ones
        all_descriptors[:10] = initial_descriptors
        descriptor_names[:10] = [
            "NumAtomStereoCenters", 
            "NumAmideBonds", 
            "MolWt", 
            "NumValenceElectrons", 
            "TPSA", 
            "MolLogP", 
            "NumHeteroatoms", 
            "NumRotatableBonds", 
            "HeavyAtomCount", 
            "FractionCSP3"
        ]
        
        return [smiles] + all_descriptors[:400], ["SMILES"] + descriptor_names[:400]
    else:
        return [smiles] + [None] * 400, ["SMILES"] + [None] * 400



def generate_descriptors_df(df) -> pd.DataFrame:
    """
    Helper function that takes a list of molecule's SMILES values and generates a DataFrame
    with SMILES and 200 features, including specified descriptors.

    Params:
    - smiles_list (list of str): List of molecule's SMILES values as strings.

    Returns:
    - DataFrame: A DataFrame with the first column as SMILES and the other 200 columns as features.
    """
    data = []
    column_names = None
    for smiles in df['SMILES']:
        descriptors, names = generate_descriptors(smiles)
        data.append(descriptors)
        if column_names is None:
            column_names = names
    
    # Create DataFrame in the format of (SMILES, |<descriptors>| = 1224)
    df = pd.DataFrame(data, columns=column_names)
    
    return df


pt_dataset.head()


pt_dataset_final = generate_descriptors_df(pt_dataset)
PRINTM('Generated new data frame with descriptors and morgan fingerprints successfully !')


pt_dataset_final.head(3)


none_count_per_column = pt_dataset_final.isna().sum()

columns_with_none = none_count_per_column[none_count_per_column > 0]
num_columns_with_none = len(columns_with_none)

print(f"Number of columns with None values: {num_columns_with_none}")


pt_dataset_final.shape


pt_dataset_final_cleaned = pt_dataset_final.dropna(axis=1, how='any')


pt_dataset_final_cleaned.shape


pt_dataset_final_cleaned


rows_with_null = pt_dataset_final_cleaned[pt_dataset_final_cleaned.isnull().any(axis=1)]

PRINTM(f'There are -> {rows_with_null.shape[0]} rows that contains missing values in some of their column values (can be in more than one)')





from rdkit import Chem
from rdkit.Chem import AllChem

def generate_morgan_fingerprints(smiles, radius, nBits):
    """
    Generate Morgan fingerprints for a given SMILES string.

    Args:
        smiles (str): The SMILES string of the molecule.
        radius (int, optional): The radius of the fingerprint. Default is 4.
        nBits (int, optional): The size of the fingerprint. Default is 1024.

    Returns:
        list: A list containing the SMILES string followed by the Morgan fingerprint values.
        list: A list containing the names of the fingerprint bits.
    """
    mol = Chem.MolFromSmiles(smiles)
    if mol is not None:
        # Compute Morgan fingerprints
        morgan_fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=nBits)
        morgan_fp_list = list(morgan_fp)
        morgan_fp_names = [f"MorganFP_{i}" for i in range(nBits)]
        
        return [smiles] + morgan_fp_list, ["SMILES"] + morgan_fp_names
    else:
        # Return None values if the molecule is invalid
        return [smiles] + [None] * nBits, ["SMILES"] + [None] * nBits



def append_morgan_fingerprints(df, smiles_column='SMILES', radius=4, nBits=1024):
    """
    Append Morgan fingerprints to a DataFrame with a SMILES column.

    Args:
        df (pd.DataFrame): The DataFrame containing the SMILES column.
        smiles_column (str, optional): The name of the column containing SMILES strings. Default is 'SMILES'.
        radius (int, optional): The radius of the Morgan fingerprint. Default is 4.
        nBits (int, optional): The size of the Morgan fingerprint. Default is 1024.

    Returns:
        pd.DataFrame: The DataFrame with Morgan fingerprints appended as new columns.
    """
    fingerprint_data = []
    fingerprint_names = None
    
    for smiles in df[smiles_column]:
        fingerprints, names = generate_morgan_fingerprints(smiles, radius=radius, nBits=nBits)
        fingerprint_data.append(fingerprints[1:]) 
        if fingerprint_names is None:
            fingerprint_names = names[1:]
    
    # Create a DataFrame for the fingerprints
    fingerprints_df = pd.DataFrame(fingerprint_data, columns=fingerprint_names)
    
    # Concatenate the original DataFrame with the fingerprints DataFrame
    df_with_fingerprints = pd.concat([df.reset_index(drop=True), fingerprints_df], axis=1)
    
    return df_with_fingerprints


pt_dataset = append_morgan_fingerprints(pt_dataset_final_cleaned)


pt_dataset.shape


pt_dataset.head()





pt_dataset.shape


pt_dataset_cp = pt_dataset.copy()


zero_columns = pt_dataset_cp.columns[(pt_dataset_cp == 0).all()]
pt_dataset_cleaned = pt_dataset_cp.drop(columns=zero_columns)
PRINTM('Droped all 0 value columns successfully !')


pt_dataset_cleaned.shape, pt_dataset_cp.shape


zero_columns = pt_dataset.columns[(pt_dataset == 0).all()]


zero_columns


one_columns = pt_dataset.columns[(pt_dataset == 1).all()]


one_columns





scaler = StandardScaler()
smiles_column = 'SMILES'


smiles_df = pt_dataset_cleaned[[smiles_column]]
data_to_scale = pt_dataset_cleaned.drop(columns=[smiles_column])

# identify columns to scale (excluding binary columns)
binary_columns = data_to_scale.columns[
    (data_to_scale.isin([0, 1])).all() & (data_to_scale.nunique() == 2)
]
columns_to_scale = data_to_scale.columns.difference(binary_columns)

# scale only the columns that are not binary
scaled_data = data_to_scale.copy()
scaled_data[columns_to_scale] = scaler.fit_transform(data_to_scale[columns_to_scale])

# concatenate the scaled data with the SMILES column
pt_dataset_scaled = pd.concat([smiles_df.reset_index(drop=True), scaled_data.reset_index(drop=True)], axis=1)


pt_dataset_scaled


rows_with_null = pt_dataset_scaled[pt_dataset_scaled.isnull().any(axis=1)]

PRINTM(f'There are -> {rows_with_null.shape[0]} rows that contains missing values in some of their column values (can be in more than one)')


pt_dataset_scaled.columns[:179]





pt_dataset_path = r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\pt_dataset_r4_scaled.csv"


pt_dataset_scaled.to_csv(pt_dataset_path, index=False)





ds_075_2_path = r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\final_dataset_2_0.75.csv"
ds_output_file_path = r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\output_file.csv"


f_df = pd.read_csv(ds_075_2_path)
s_df = pd.read_csv(ds_output_file_path)


f_df.head()


s_df.head()


f_df_smiles = f_df['smiles'].unique()
s_df_smiles = s_df['SMILES'].unique()

len(f_df_smiles) , len(s_df_smiles)


all_smiles_df = pd.DataFrame(s_df_smiles, columns=['SMILES'])


morgan_fingerprints_mapping_dataset = all_smiles_df.copy()
chemical_descriptors_mapping_dataset = all_smiles_df.copy()


morgan_fingerprints_mapping_dataset = append_morgan_fingerprints(morgan_fingerprints_mapping_dataset)


morgan_fingerprints_mapping_dataset


chemical_descriptors_mapping_dataset = generate_descriptors_df(chemical_descriptors_mapping_dataset)


chemical_descriptors_mapping_dataset


chemical_descriptors_mapping_dataset = chemical_descriptors_mapping_dataset.dropna(axis=1, how='any')


chemical_descriptors_mapping_dataset


zero_columns = chemical_descriptors_mapping_dataset.columns[(chemical_descriptors_mapping_dataset == 0).all()]
zero_columns


chemical_descriptors_mapping_dataset = chemical_descriptors_mapping_dataset.drop(columns=zero_columns)


chemical_descriptors_mapping_dataset


chemical_descriptors_mapping_dataset['NumAtomStereoCenters'].unique()


chemical_descriptors_mapping_dataset['NumAmideBonds'].unique()


chemical_descriptors_mapping_dataset['fr_thiophene'].unique()


chemical_descriptors_mapping_dataset_c = chemical_descriptors_mapping_dataset.copy()





scaler = StandardScaler()

chemical_descriptors_mapping_dataset_smiles = chemical_descriptors_mapping_dataset_c[['SMILES']]
data_to_scale = chemical_descriptors_mapping_dataset_c.drop(columns=['SMILES'])

# identify columns to scale (excluding binary columns)
binary_columns = data_to_scale.columns[
    (data_to_scale.isin([0, 1])).all() & (data_to_scale.nunique() == 2)
]
columns_to_scale = data_to_scale.columns.difference(binary_columns)

# scale only the columns that are not binary
scaled_data = data_to_scale.copy()
scaled_data[columns_to_scale] = scaler.fit_transform(data_to_scale[columns_to_scale])

# concatenate the scaled data with the SMILES column
chemical_descriptors_mapping_dataset_scaled = pd.concat([chemical_descriptors_mapping_dataset_smiles.reset_index(drop=True), scaled_data.reset_index(drop=True)], axis=1)


chemical_descriptors_mapping_dataset_scaled


binary_columns


binary_columns.values


chemical_descriptors_mapping_dataset_scaled[binary_columns.values]


morgan_fingerprints_mapping_dataset.to_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\SMILES & PPI Features\smiles_morgan_fingerprints_dataset.csv", index=False)
chemical_descriptors_mapping_dataset_scaled.to_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\SMILES & PPI Features\smiles_chem_descriptors_mapping_dataset.csv", index=False)







import os
import pandas as pd





esm_features_path = r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\esm_features.csv"
custom_sequence_features_path = r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\custom_sequence_features.csv"
fegs_features_path = r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\fegs_features.csv"


esm_features_df = pd.read_csv(esm_features_path)
custom_features_df = pd.read_csv(custom_sequence_features_path)
fegs_features_df = pd.read_csv(fegs_features_path)


fegs_features_df.head()


esm_features_df.head()


custom_features_df.head()


esm_features_df.columns


custom_features_df.columns


fegs_features_df.columns


custom_features_df[['4700']].head()


# Convert uniprots column name & make it the first column in the data frame
custom_features_df.rename(columns={'4700': 'UniProt_ID'}, inplace=True)
fegs_features_df.rename(columns={'uniprotID':'UniProt_ID'}, inplace=True)

cols = ['UniProt_ID'] + [col for col in custom_features_df if col != 'UniProt_ID']
custom_features_df = custom_features_df[cols]

cols = ['UniProt_ID'] + [col for col in fegs_features_df if col != 'UniProt_ID']
fegs_features_df = fegs_features_df[cols]


custom_features_df.head()


custom_features_uniprots = custom_features_df[['UniProt_ID']]
esm_features_uniprots = esm_features_df[['UniProt_ID']]
fegs_features_uniprots = fegs_features_df[['UniProt_ID']]


custom_features_uniprots.shape , fegs_features_uniprots.shape, esm_features_uniprots.shape,


unique_custom_uniprots = custom_features_uniprots['UniProt_ID'].nunique()
unique_esm_uniprots = esm_features_uniprots['UniProt_ID'].nunique()
unique_fegs_uniprots = fegs_features_uniprots['UniProt_ID'].nunique()

print(f"Number of unique UniProt IDs in custom_features_df: {unique_custom_uniprots}")
print(f"Number of unique UniProt IDs in fegs_features_df: {unique_fegs_uniprots}")
print(f"Number of unique UniProt IDs in esm_features_df: {unique_esm_uniprots}")


final_ds_path = r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\final_dataset_2_0.75.csv"
final_df = pd.read_csv(final_ds_path)





from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()


# Scale the values of all PPI features data frames by standard scaler
columns_to_scale = custom_features_df.columns.difference(['UniProt_ID'])
custom_features_df[columns_to_scale] = scaler.fit_transform(custom_features_df[columns_to_scale])

columns_to_scale = fegs_features_df.columns.difference(['UniProt_ID'])
fegs_features_df[columns_to_scale] = scaler.fit_transform(fegs_features_df[columns_to_scale])

columns_to_scale = esm_features_df.columns.difference(['UniProt_ID'])
esm_features_df[columns_to_scale] = scaler.fit_transform(esm_features_df[columns_to_scale])


custom_features_df.head()


fegs_features_df.head()


esm_features_df.head()


combined_uniprots = pd.concat([final_df['uniprot_id1'], final_df['uniprot_id2']])
unique_uniprots = combined_uniprots.nunique()

print(f"Number of unique UniProt IDs in both in final_dataset_2_0.75: {unique_uniprots}")


merged_uniprots = pd.merge(custom_features_df, esm_features_df, on='UniProt_ID', how='inner')
merged_uniprots = pd.merge(fegs_features_df, merged_uniprots, on='UniProt_ID', how='inner')


merged_uniprots['UniProt_ID'].nunique()





missing_uniprot_id = esm_features_df[~esm_features_df['UniProt_ID'].isin(merged_uniprots['UniProt_ID'])]

print("Missing UniProt_ID and its values from esm_features_df:\n")
print(missing_uniprot_id['UniProt_ID'])


new_row_data = {col: missing_uniprot_id.iloc[0][col] for col in missing_uniprot_id.columns}

for col in merged_uniprots.columns:
    if col not in new_row_data:
        new_row_data[col] = 0

new_row_df = pd.DataFrame([new_row_data])


new_row_df


merged_uniprots = pd.concat([merged_uniprots, new_row_df], ignore_index=True)


merged_uniprots['UniProt_ID'].nunique()


merged_uniprots.head()





current_columns = merged_uniprots.columns
new_column_names = ['UniProt_ID'] + [f'Feature_{i+1}' for i in range(len(current_columns) - 1)]

# Create a dictionary mapping current column names to new names
rename_dict = dict(zip(current_columns, new_column_names))

merged_uniprots.rename(columns=rename_dict, inplace=True)


merged_uniprots


merged_uniprots.to_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\merged_ppi_features.csv", index=False)




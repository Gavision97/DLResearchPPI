


import os
import pandas as pd





esm_features_path = r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\esm_features.csv"
custom_sequence_features_path = r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\custom_sequence_features.csv"
fegs_features_path = r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\fegs_features.csv"


esm_features_df = pd.read_csv(esm_features_path)
custom_features_df = pd.read_csv(custom_sequence_features_path)
fegs_features_df = pd.read_csv(fegs_features_path)


fegs_features_df.head()


esm_features_df.head()


custom_features_df.head()


esm_features_df.columns


custom_features_df.columns


fegs_features_df.columns


custom_features_df[['4700']].head()


# Convert uniprots column name & make it the first column in the data frame
custom_features_df.rename(columns={'4700': 'UniProt_ID'}, inplace=True)
fegs_features_df.rename(columns={'uniprotID':'UniProt_ID'}, inplace=True)

cols = ['UniProt_ID'] + [col for col in custom_features_df if col != 'UniProt_ID']
custom_features_df = custom_features_df[cols]

cols = ['UniProt_ID'] + [col for col in fegs_features_df if col != 'UniProt_ID']
fegs_features_df = fegs_features_df[cols]


custom_features_df.head()


custom_features_uniprots = custom_features_df[['UniProt_ID']]
esm_features_uniprots = esm_features_df[['UniProt_ID']]
fegs_features_uniprots = fegs_features_df[['UniProt_ID']]


custom_features_uniprots.shape , fegs_features_uniprots.shape, esm_features_uniprots.shape,


unique_custom_uniprots = custom_features_uniprots['UniProt_ID'].nunique()
unique_esm_uniprots = esm_features_uniprots['UniProt_ID'].nunique()
unique_fegs_uniprots = fegs_features_uniprots['UniProt_ID'].nunique()

print(f"Number of unique UniProt IDs in custom_features_df: {unique_custom_uniprots}")
print(f"Number of unique UniProt IDs in fegs_features_df: {unique_fegs_uniprots}")
print(f"Number of unique UniProt IDs in esm_features_df: {unique_esm_uniprots}")


unique_uniprot_esm = esm_features_df['UniProt_ID'].unique()

# Filter custom_features_df to keep only rows with UniProt_IDs in esm_features_df
custom_filtered_df = custom_features_df[custom_features_df['UniProt_ID'].isin(unique_uniprot_esm)]

# Filter fegs_features_df to keep only rows with UniProt_IDs in esm_features_df
fegs_filtered_df = fegs_features_df[fegs_features_df['UniProt_ID'].isin(unique_uniprot_esm)]

print("Unique UniProt_IDs in esm_features_df:", len(unique_uniprot_esm))
print("Unique UniProt_IDs in custom_filtered_df:", custom_filtered_df['UniProt_ID'].nunique())
print("Unique UniProt_IDs in fegs_filtered_df:", fegs_filtered_df['UniProt_ID'].nunique())


set_uniprot_esm = set(unique_uniprot_esm)
set_uniprot_custom = set(unique_uniprot_custom)
set_uniprot_fegs = set(unique_uniprot_fegs)


set_uniprot_esm - set_uniprot_custom 


new_row = pd.DataFrame({
    'UniProt_ID': ['C5J4T0'],
    **{col: [0] for col in custom_filtered_df.columns if col != 'UniProt_ID'}
})

custom_filtered_df = pd.concat([custom_filtered_df, new_row], ignore_index=True)


print("Unique UniProt_IDs in custom_filtered_df:", custom_filtered_df['UniProt_ID'].nunique())
unique_uniprot_custom = custom_filtered_df['UniProt_ID'].unique()


set_uniprot_custom = set(unique_uniprot_custom)


custom_filtered_df.tail()


custom_filtered_df.shape, fegs_filtered_df.shape, esm_features_df.shape


def rename_columns(df, prefix):
    uniprot_id = df['UniProt_ID']
    
    # Rename feature columns
    feature_columns = df.columns[1:]  # Exclude 'UniProt_ID'
    new_feature_columns = [f'{prefix}_f{i}' for i in range(len(feature_columns))]
    
    renamed_df = pd.DataFrame(df.values, columns=['UniProt_ID'] + new_feature_columns)
    
    return renamed_df

custom_filtered_df_renamed = rename_columns(custom_filtered_df, 'cust')
fegs_filtered_df_renamed = rename_columns(fegs_filtered_df, 'fegs')
esm_features_df_renamed = rename_columns(esm_features_df, 'esm')


custom_filtered_df_renamed.head()


fegs_filtered_df_renamed.head()


esm_features_df_renamed.head()


esm_features_df_renamed.to_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\esm_features.csv", index=False)
custom_filtered_df_renamed.to_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\custom_features.csv", index=False)
fegs_filtered_df_renamed.to_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\fegs_features.csv", index=False)





esm_df = pd.read_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\esm_features.csv")
custom_df = pd.read_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\custom_features.csv")
fegs_df = pd.read_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\fegs_features.csv")


esm_df.shape, custom_df.shape, fegs_df.shape





# remove duplicates based on 'UniProt_ID'
custom_df = custom_df.drop_duplicates(subset='UniProt_ID')
fegs_df = fegs_df.drop_duplicates(subset='UniProt_ID')


custom_df.shape , fegs_df.shape





set_esm = set(esm_df['UniProt_ID'])
set_custom = set(custom_df['UniProt_ID'])
set_fegs = set(fegs_df['UniProt_ID'])

are_all_equal = (set_esm == set_custom) and (set_esm == set_fegs)

print("All UniProt_ID sets are equal:", are_all_equal)


custom_df = custom_df[custom_df['UniProt_ID'].isin(esm_df['UniProt_ID'])]
fegs_df = fegs_df[fegs_df['UniProt_ID'].isin(esm_df['UniProt_ID'])]

# Reorder custom_df and fegs_df to match the order of UniProt_IDs in esm_df
custom_df = custom_df.set_index('UniProt_ID').reindex(esm_df['UniProt_ID']).reset_index()
fegs_df = fegs_df.set_index('UniProt_ID').reindex(esm_df['UniProt_ID']).reset_index()


esm_df['UniProt_ID'].head() , fegs_df['UniProt_ID'].head(), custom_df['UniProt_ID'].head()


esm_df.shape[0] == fegs_df.shape[0] == custom_df.shape[0]


from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()


# Scale the values of all PPI features data frames by standard scaler
columns_to_scale = custom_df.columns.difference(['UniProt_ID'])
custom_df[columns_to_scale] = scaler.fit_transform(custom_df[columns_to_scale])

columns_to_scale = fegs_df.columns.difference(['UniProt_ID'])
fegs_df[columns_to_scale] = scaler.fit_transform(fegs_df[columns_to_scale])

#columns_to_scale = esm_features_df.columns.difference(['UniProt_ID'])
#esm_features_df[columns_to_scale] = scaler.fit_transform(esm_features_df[columns_to_scale])


esm_df.to_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\esm_features.csv", index=False)
custom_df.to_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\custom_features.csv", index=False)
fegs_df.to_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\fegs_features.csv", index=False)


esm_df = pd.read_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\esm_features.csv")
custom_df = pd.read_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\custom_features.csv")
fegs_df =  pd.read_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\fegs_features.csv")


final_ds_path = r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\final_dataset_2_0.75.csv"
final_df = pd.read_csv(final_ds_path)


df = pd.read_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\DLIP_folds_2_0.8\train_fold2.csv")


df


esm_df


mapping_df = pd.read_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\idmapping_unip.tsv", delimiter = "\t")

def convert_uniprot_ids(dataset, mapping_df):
    # Create a dictionary from the mapping dataframe
    mapping_dict = mapping_df.set_index('From')['Entry'].to_dict()

    # Map the uniprot_id1 and uniprot_id2 columns to their respective Entry values
    dataset['uniprot_id1'] = dataset['uniprot_id1'].map(mapping_dict)
    dataset['uniprot_id2'] = dataset['uniprot_id2'].map(mapping_dict)
    return dataset.drop_duplicates()


df = convert_uniprot_ids(df, mapping_df)


uniprot_set_df = set(pd.concat([df['uniprot_id1'], df['uniprot_id2']]).unique())

# Step 2: Create a set from the 'UniProt_ID' column in esm_df
uniprot_set_esm_df = set(esm_df['UniProt_ID'].unique())


len(uniprot_set_df)


len(uniprot_set_esm_df)


uniprot_set_df - uniprot_set_esm_df


final_df.head()


unique_custom_uniprots = set(custom_features_uniprots['UniProt_ID'].unique())
unique_esm_uniprots = set(esm_features_uniprots['UniProt_ID'].unique())
unique_fegs_uniprots = set(fegs_features_uniprots['UniProt_ID'].unique())


len(unique_esm_uniprots), len(unique_custom_uniprots), len(unique_fegs_uniprots)


final_custom_uniprots = unique_custom_uniprots - unique_esm_uniprots
final_fegs_uniprots = unique_fegs_uniprots - unique_esm_uniprots





from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()


# Scale the values of all PPI features data frames by standard scaler
columns_to_scale = custom_features_df.columns.difference(['UniProt_ID'])
custom_features_df[columns_to_scale] = scaler.fit_transform(custom_features_df[columns_to_scale])

columns_to_scale = fegs_features_df.columns.difference(['UniProt_ID'])
fegs_features_df[columns_to_scale] = scaler.fit_transform(fegs_features_df[columns_to_scale])

columns_to_scale = esm_features_df.columns.difference(['UniProt_ID'])
esm_features_df[columns_to_scale] = scaler.fit_transform(esm_features_df[columns_to_scale])


custom_features_df.head()


fegs_features_df.head()


esm_features_df.head()


combined_uniprots = pd.concat([final_df['uniprot_id1'], final_df['uniprot_id2']])
unique_uniprots = combined_uniprots.nunique()

print(f"Number of unique UniProt IDs in both in final_dataset_2_0.75: {unique_uniprots}")


merged_uniprots = pd.merge(custom_features_df, esm_features_df, on='UniProt_ID', how='inner')
merged_uniprots = pd.merge(fegs_features_df, merged_uniprots, on='UniProt_ID', how='inner')


merged_uniprots['UniProt_ID'].nunique()





missing_uniprot_id = esm_features_df[~esm_features_df['UniProt_ID'].isin(merged_uniprots['UniProt_ID'])]

print("Missing UniProt_ID and its values from esm_features_df:\n")
print(missing_uniprot_id['UniProt_ID'])


new_row_data = {col: missing_uniprot_id.iloc[0][col] for col in missing_uniprot_id.columns}

for col in merged_uniprots.columns:
    if col not in new_row_data:
        new_row_data[col] = 0

new_row_df = pd.DataFrame([new_row_data])


new_row_df


merged_uniprots = pd.concat([merged_uniprots, new_row_df], ignore_index=True)


merged_uniprots['UniProt_ID'].nunique()


merged_uniprots.head()





current_columns = merged_uniprots.columns
new_column_names = ['UniProt_ID'] + [f'Feature_{i+1}' for i in range(len(current_columns) - 1)]

# Create a dictionary mapping current column names to new names
rename_dict = dict(zip(current_columns, new_column_names))

merged_uniprots.rename(columns=rename_dict, inplace=True)


merged_uniprots


merged_uniprots.to_csv(r"C:\Users\gavvi\Desktop\Programming\GitHub\DeepLearningResearchStarship\Research Projects\Project 5 Building Model for Research Pipeline\datasets\merged_ppi_features.csv", index=False)




{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e12a9e9c-b901-4ed0-965a-c2dc4f3f837e",
   "metadata": {},
   "source": [
    "# Pre Train Chemprop Model #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcec6a4-5f75-4ba0-860f-a42b21a6cb6a",
   "metadata": {},
   "source": [
    "## Import Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8154c685-2c72-416a-99c2-c0405da05707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import chemprop\n",
    "from chemprop import data, featurizers, models\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# import necessary libraries for Chemberta model\n",
    "from transformers import RobertaTokenizer, RobertaModel, RobertaConfig, AdamW, get_linear_schedule_with_warmup , BertModel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors, Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f205d5-fc7f-4041-98fe-d733db10df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRINT() -> None: print(f\"{'-'*80}\\nDone\\n{'-'*80}\")\n",
    "def PRINTC() -> None: print(f\"{'-'*80}\")\n",
    "def PRINTM(M) -> None: print(f\"{'-'*80}\\n{M}\\n{'-'*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292be2e8-c26d-47c5-875e-ec1d8b8a42b1",
   "metadata": {},
   "source": [
    "## Verify GPU Availability ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca0e2bd-ebdf-469d-b3a3-2719d508ca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 11 16:52:49 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX 6000 Ada Gene...    On  |   00000000:01:00.0 Off |                  Off |\n",
      "| 30%   31C    P8             29W /  300W |       2MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19b9a93-d655-4fc5-8113-9e492c4d34d5",
   "metadata": {},
   "source": [
    "For this task, we'll use the BGU cluster GPU `NVIDIA RTX 6000 Ada Generation` to achieve better performance during the training of our pre-trained and fine-tuned models, allowing for more efficient processing of large datasets and complex computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94354f56-7aa2-4105-a2e0-8a0a8efc3f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "GPU is available.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    PRINTM(f\"GPU is available.\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    PRINTM(f\"GPU is not available. Using CPU instead.\")\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953e7dc3-c267-4368-b488-d467d19ac35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "PyTorch version: 2.3.1+cu121\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "CUDA available: True\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "CUDA version:  12.1\n",
      "--------------------------------------------------------------------------------\n",
      "CUDA device: NVIDIA RTX 6000 Ada Generation\n"
     ]
    }
   ],
   "source": [
    "PRINTM(f\"PyTorch version: {torch.__version__}\")\n",
    "PRINTM(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "PRINTM(f\"CUDA version:  {torch.version.cuda}\")\n",
    "print(f\"CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No CUDA'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d1191-c4b1-4ff3-91d8-195e9adb28ba",
   "metadata": {},
   "source": [
    "# Fine Tune Chemprop Pre-trained Model & Generate AUVG_PPI Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a0a9aa2-a42a-4209-9b56-7ec0a9592a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(dataset, features_df):\n",
    "    # Merge features for uniprot_id1\n",
    "    dataset = dataset.merge(features_df, how='left', left_on='uniprot_id1', right_on='UniProt_ID', suffixes=('', '_id1'))\n",
    "    dataset = dataset.drop(columns=['UniProt_ID'])\n",
    "    \n",
    "    # Merge features for uniprot_id2\n",
    "    features_df_renamed = features_df.add_suffix('_id2')\n",
    "    features_df_renamed = features_df_renamed.rename(columns={'UniProt_ID_id2': 'UniProt_ID'})\n",
    "    dataset = dataset.merge(features_df_renamed, how='left', left_on='uniprot_id2', right_on='UniProt_ID', suffixes=('', '_id2'))\n",
    "    dataset = dataset.drop(columns=['UniProt_ID', 'uniprot_id1', 'uniprot_id2'])\n",
    "    \n",
    "    return dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ef953aa-40c8-4675-ab6f-c97e9be9dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_uniprot_ids(dataset, mapping_df):\n",
    "    # Create a dictionary from the mapping dataframe\n",
    "    mapping_dict = mapping_df.set_index('From')['Entry'].to_dict()\n",
    "\n",
    "    # Map the uniprot_id1 and uniprot_id2 columns to their respective Entry values\n",
    "    dataset['uniprot_id1'] = dataset['uniprot_id1'].map(mapping_dict)\n",
    "    dataset['uniprot_id2'] = dataset['uniprot_id2'].map(mapping_dict)\n",
    "    return dataset.drop_duplicates()\n",
    "    \n",
    "def merge_datasets(dataset, features_df):\n",
    "    # Merge features for uniprot_id1\n",
    "    dataset = dataset.merge(features_df, how='left', left_on='uniprot_id1', right_on='UniProt_ID', suffixes=('', '_id1'))\n",
    "    dataset = dataset.drop(columns=['UniProt_ID'])\n",
    "    \n",
    "    # Merge features for uniprot_id2\n",
    "    features_df_renamed = features_df.add_suffix('_id2')\n",
    "    features_df_renamed = features_df_renamed.rename(columns={'UniProt_ID_id2': 'UniProt_ID'})\n",
    "    dataset = dataset.merge(features_df_renamed, how='left', left_on='uniprot_id2', right_on='UniProt_ID', suffixes=('', '_id2'))\n",
    "    dataset = dataset.drop(columns=['UniProt_ID', 'uniprot_id1', 'uniprot_id2'])\n",
    "    \n",
    "    return dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ab5b0f-147b-44ee-9827-410d87974bc4",
   "metadata": {},
   "source": [
    "## Finetune Step ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "061d1ac9-545e-4bce-9244-799ce5390949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedChempropModel(nn.Module):\n",
    "    def __init__(self, checkpoints_path, batch_size):\n",
    "        super(PretrainedChempropModel, self).__init__()\n",
    "        self.mpnn = self.load_pretrained_model(checkpoints_path)\n",
    "        self.featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def forward(self, smiles):\n",
    "        # Prepare the data in order to generate embeddings from modulators SMILES\n",
    "        self.smiles_data = [data.MoleculeDatapoint.from_smi(smi) for smi in smiles]\n",
    "        self.smiles_dset = data.MoleculeDataset(self.smiles_data, featurizer=self.featurizer)\n",
    "        self.smiles_loader = data.build_dataloader(self.smiles_dset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        embeddings = [\n",
    "            # Etract the embedding from the last FFN layer, i.e., before the final prediction(thus i=-1)\n",
    "            self.mpnn.predictor.encode(self.fingerprints_from_batch_molecular_graph(batch, self.mpnn), i=-1) \n",
    "            for batch in self.smiles_loader\n",
    "        ]\n",
    "        #print(embeddings)\n",
    "        if not embeddings:\n",
    "             return torch.empty(0, device=device)\n",
    "        embeddings = torch.cat(embeddings, 0).to(device)\n",
    "        return embeddings\n",
    "\n",
    "    def fingerprints_from_batch_molecular_graph(self, batch, mpnn):\n",
    "        batch.bmg.to(device)\n",
    "        H_v = mpnn.message_passing(batch.bmg, batch.V_d)\n",
    "        H = mpnn.agg(H_v, batch.bmg.batch)\n",
    "        H = mpnn.bn(H)\n",
    "        fingerprints = H if batch.X_d is None else torch.cat((H, mpnn.batch.X_d_transform(X_d)), 1)\n",
    "        return fingerprints\n",
    "\n",
    "    def load_pretrained_model(self, checkpoints_path):\n",
    "        mpnn = models.MPNN.load_from_checkpoint(checkpoints_path).to(device)\n",
    "        return mpnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6afa3216-ac3d-4af1-b53d-a7c9357f9cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChemBERTaPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChemBERTaPT, self).__init__()\n",
    "        self.model_name = \"DeepChem/ChemBERTa-77M-MTR\"\n",
    "        self.chemberta = RobertaModel.from_pretrained(self.model_name)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        bert_output = self.chemberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return bert_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af01f2a8-c429-4f49-8e12-ec45f015667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUVG_PPI(nn.Module):\n",
    "    def __init__(self, pretrained_chemprop_model, chemberta_model, dropout):\n",
    "        super(AUVG_PPI, self).__init__()\n",
    "        self.pretrained_chemprop_model = pretrained_chemprop_model\n",
    "        self.chemberta_model = chemberta_model\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # MLP for ppi_features\n",
    "        self.ppi_mlp = nn.Sequential(\n",
    "            nn.Linear(in_features=6558 + 6558, out_features=2048),\n",
    "            nn.ReLU(),\n",
    "            #nn.BatchNorm1d(2048),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features=2048, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            #nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features=512, out_features=320)\n",
    "        )\n",
    "\n",
    "        self.fp_mlp = nn.Sequential(\n",
    "            nn.Linear(in_features=2100, out_features=1050),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features=1050, out_features=600), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features=600, out_features=300)\n",
    "        )\n",
    "\n",
    "        # Additional layrs in order to concatinate chemprop fingerprints, chemBERTa embeddings & ppi features all together\n",
    "        self.additional_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=300 + 384 + 320, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features=128, out_features=1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, bmg, proteins, input_ids, attention_mask):\n",
    "        # Forward pass batch mol graph through pretrained chemprop model in order to get fingerprints embeddings\n",
    "        # Afterwards, pass the fingerprints through MLP layer\n",
    "        fingerprints = self.pretrained_chemprop_model(bmg)\n",
    "        fingerprints = self.fp_mlp(fingerprints)\n",
    "\n",
    "        # Forward pass ids & attention mask in through chemBERTa pretrained model in order to get embeddings\n",
    "        chemberta_embeddings = self.chemberta_model(input_ids, attention_mask)\n",
    "\n",
    "        # Move PPI features to device and then pass them through MLP layer\n",
    "        ppi_features = proteins.to(device)\n",
    "        ppi_features = self.ppi_mlp(ppi_features)\n",
    "\n",
    "        # Concatinate chemprop fingerprints embeddings, chemberta embeddings and PPI embeddings together into one tensor\n",
    "        # Afterwards, pass them through MLP layer and make prediction\n",
    "        combined_embeddings = torch.cat([fingerprints, chemberta_embeddings, ppi_features], dim=1).to(device)\n",
    "        output = self.additional_layers(combined_embeddings)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "    def train_model(self, num_epochs, train_loader, val_loader, optimizer, criterion, device):\n",
    "        PRINTM(f'Start training !')\n",
    "        for epoch in range(num_epochs):\n",
    "            start_time = time.time()\n",
    "            self.train()\n",
    "            running_loss = 0.0\n",
    "            for i, (batch_smiles, batch_protein_features, batch_input_ids, batch_attention_mas, batch_labels) in enumerate(train_loader):\n",
    "                \n",
    "                # Move tensors to the configured device\n",
    "                batch_attention_mas = batch_attention_mas.to(device)\n",
    "                batch_input_ids = batch_input_ids.to(device)\n",
    "                batch_protein_features = batch_protein_features.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(batch_smiles, batch_protein_features, batch_input_ids, batch_attention_mas)\n",
    "                loss = criterion(outputs.squeeze(), batch_labels)\n",
    "    \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                #running_loss += loss.item()\n",
    "                #if i % 100 == 99 and i > 0:\n",
    "                    #print(f\"Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss / 100:.4f}\")\n",
    "                    #running_loss = 0.0\n",
    "    \n",
    "            # Validate the model on the validation set\n",
    "            val_loss, val_accuracy, val_auc = self.validate_model(val_loader, criterion, device)\n",
    "            end_time = time.time()\n",
    "            epoch_time = (end_time - start_time) / 60\n",
    "            PRINTC()\n",
    "            print(f\"Epoch: {epoch+1}\")\n",
    "            print(f\"Validation BCELoss: {val_loss:.5f}\")\n",
    "            print(f\"Validation Accuracy (>0.8): {val_accuracy:.2f}\")\n",
    "            print(f\"Validation AUC: {val_auc:.5f}\")\n",
    "            print(f\"Epoch time: {epoch_time:.2f} minutes\")\n",
    "            PRINTC()\n",
    "    \n",
    "        print(\"Finish training !\")\n",
    "\n",
    "    def test_model(self, test_dataset,\n",
    "                   criterion,batch_size,\n",
    "                   shuffle, device):\n",
    "        test_dataset = MoleculeDataset(test_dataset)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        self.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_outputs = []\n",
    "        with torch.no_grad():\n",
    "            for batch_smiles, batch_protein_features, batch_input_ids, batch_attention_mas, batch_labels in test_loader:\n",
    "                # Move tensors to the configured device\n",
    "\n",
    "                batch_attention_mas = batch_attention_mas.to(device)\n",
    "                batch_input_ids = batch_input_ids.to(device)\n",
    "                batch_protein_features = batch_protein_features.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "    \n",
    "                outputs = self(batch_smiles, batch_protein_features, batch_input_ids, batch_attention_mas)\n",
    "\n",
    "                loss = criterion(outputs.squeeze(), batch_labels)\n",
    "                test_loss += loss.item()\n",
    "    \n",
    "                all_labels.extend(batch_labels.cpu().numpy())  \n",
    "                all_outputs.extend(outputs.squeeze().cpu().numpy())  \n",
    "    \n",
    "                predicted = (outputs.squeeze() > 0.8).float()\n",
    "                total += batch_labels.size(0)\n",
    "                correct += (predicted == batch_labels).sum().item()\n",
    "    \n",
    "        test_loss /= len(test_loader)\n",
    "        accuracy = correct / total\n",
    "        test_auc = roc_auc_score(all_labels, all_outputs) \n",
    "        PRINTC()\n",
    "        #print(f\"Test BCELoss: {test_loss:.5f}\")\n",
    "        #print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"Test AUC: {test_auc:.5f}\")\n",
    "        PRINTC()\n",
    "\n",
    "    def validate_model(self, val_loader, criterion, device):\n",
    "        self.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_outputs = []\n",
    "        with torch.no_grad():\n",
    "            for batch_smiles, batch_protein_features, batch_input_ids, batch_attention_mas, batch_labels in val_loader:\n",
    "                # Move tensors to the configured device\n",
    "                batch_input_ids = batch_input_ids.to(device)\n",
    "                batch_attention_mas = batch_attention_mas.to(device)\n",
    "                batch_protein_features = batch_protein_features.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "    \n",
    "                outputs = self(batch_smiles, batch_protein_features, batch_input_ids, batch_attention_mas)\n",
    "                loss = criterion(outputs.squeeze(), batch_labels)\n",
    "                val_loss += loss.item()\n",
    "    \n",
    "                all_labels.extend(batch_labels.cpu().numpy())  \n",
    "                all_outputs.extend(outputs.squeeze().cpu().numpy())  \n",
    "    \n",
    "                predicted = (outputs.squeeze() > 0.8).float()\n",
    "                total += batch_labels.size(0)\n",
    "                correct += (predicted == batch_labels).sum().item()\n",
    "    \n",
    "        val_loss /= len(val_loader)\n",
    "        accuracy = correct / total\n",
    "        val_auc = roc_auc_score(all_labels, all_outputs)  \n",
    "        return val_loss, accuracy, val_auc\n",
    "\n",
    "    def cross_validate(self, dataset,\n",
    "                       num_folds=5,num_epochs=10,\n",
    "                       batch_size=32,\n",
    "                       learning_rate=0.0001, weight_decay=1e-5,\n",
    "                       shuffle=True, device='cuda'):\n",
    "        kf = KFold(n_splits=num_folds, shuffle=shuffle)\n",
    "        \n",
    "        fold_results = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "            \n",
    "            print(f\"Fold {fold+1}/{num_folds}\")\n",
    "            \n",
    "            # Split dataset\n",
    "            train_subset = dataset.iloc[train_idx].reset_index(drop=True)\n",
    "            val_subset = dataset.iloc[val_idx].reset_index(drop=True)\n",
    "            \n",
    "            train_dataset = MoleculeDataset(train_subset)\n",
    "            val_dataset = MoleculeDataset(val_subset)\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "            \n",
    "            criterion = nn.BCELoss()\n",
    "            optimizer = optim.Adam(self.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "            \n",
    "            self.train_model(num_epochs, train_loader, val_loader, optimizer, criterion, device)\n",
    "            \n",
    "            # Validate the model\n",
    "            val_loss, val_accuracy, val_auc = self.validate_model(val_loader, criterion, device)\n",
    "            fold_results.append((val_loss, val_accuracy, val_auc))\n",
    "\n",
    "            PRINTC()\n",
    "            print(f\"Fold {fold+1} - Validation BCELoss: {val_loss:.5f}, Accuracy: {val_accuracy:.2f}, AUC: {val_auc:.5f}\")\n",
    "            PRINTC()\n",
    "            \n",
    "        avg_val_loss = sum([result[0] for result in fold_results]) / num_folds\n",
    "        avg_val_accuracy = sum([result[1] for result in fold_results]) / num_folds\n",
    "        avg_val_auc = sum([result[2] for result in fold_results]) / num_folds\n",
    "        \n",
    "        print(f\"\\nAverage Validation BCELoss: {avg_val_loss:.5f}\")\n",
    "        print(f\"Average Validation Accuracy: {avg_val_accuracy:.2f}\")\n",
    "        print(f\"Average Validation AUC: {avg_val_auc:.5f}\")\n",
    "        \n",
    "        return fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afcbdf9f-e4e0-4fd3-9471-e780c0728629",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.data = ds\n",
    "        self.features = self.data.drop(columns=['smiles', 'label']).astype(np.float32)\n",
    "\n",
    "        # necessary features for ChemBERTa model\n",
    "        self.smiles_list = self.data['smiles'].tolist()\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained(\"DeepChem/ChemBERTa-77M-MTR\")\n",
    "        self.encoded_smiles = self.tokenizer(self.smiles_list, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        smiles = self.data.iloc[idx, 0]\n",
    "        label = np.array(self.data.iloc[idx, 1], dtype=np.float32)  \n",
    "        features = np.array(self.features.iloc[idx].values, dtype=np.float32)\n",
    "\n",
    "        input_ids = self.encoded_smiles[\"input_ids\"][idx]\n",
    "        attention_mask = self.encoded_smiles[\"attention_mask\"][idx]\n",
    "        \n",
    "        return (smiles, features, input_ids, attention_mask, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e569e55-f80f-468c-9e95-14524143e452",
   "metadata": {},
   "source": [
    "## Train the Model on Finetuned Datasets (multi_ppim_fold_2_0.8)  ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbd14c3-a534-43c5-bdc2-1aa6bccd110e",
   "metadata": {},
   "source": [
    "### Load & Prepare the Dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b276610-4b98-48a7-80ed-b290391d67e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Folder content:\n",
      "\n",
      "['train_fold1.csv', 'train_fold3.csv', 'test_fold3.csv', 'train_fold5.csv', 'test_fold5.csv', 'test_fold2.csv', 'test_fold4.csv', 'train_fold4.csv', 'test_fold1.csv', 'train_fold2.csv']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ds_folder_path = os.path.join('datasets', 'finetune_dataset', 'multi_ppim_folds_2_0.8')\n",
    "all_files = os.listdir(ds_folder_path)\n",
    "\n",
    "PRINTM(f'Folder content:\\n\\n{all_files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9295d4c-ae37-40f4-8e4b-f3a4f1fad797",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "\n",
    "# Read each CSV file into a dataframe and store it in the dictionary\n",
    "for file in all_files:\n",
    "    file_path = os.path.join(ds_folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_name = file.replace('.csv', '_df')\n",
    "    dataframes[df_name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf82d1a-6a0d-4fb1-b2bd-54836e82418b",
   "metadata": {},
   "source": [
    "#### Add PPI Features to Train Dataframe ####\n",
    "\n",
    "Before starting the training process on the training dataset, we'll add PPI features to the train and test datasets to utilize the model we built earlier. For this, we'll use the `esm_features.csv` dataset, which contains UniProt IDs with their features generated by Facebook's LLM algorithm called *ESM*. We'll also use the `idmapping_unip.tsv` file to map the correct features to the corresponding UniProt IDs in our training & testing datasets, using two helper functions. This process is identical to the one we used when we initially trained the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d447c08-ad11-4177-96c9-b56a85a268c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Done\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "uniprot_mapping = pd.read_csv(os.path.join('datasets', 'idmapping_unip.tsv'), delimiter = \"\\t\")\n",
    "ppi_features_df = pd.read_csv(os.path.join('datasets', 'merged_ppi_features.csv'))\n",
    "PRINT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d601d174-176f-46c9-bdb6-e792ac9eaf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Done inverse mapping & merging successfully !\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for df_name in dataframes.keys():\n",
    "    dataframes[df_name] = convert_uniprot_ids(dataframes[df_name], uniprot_mapping)\n",
    "    dataframes[df_name] = merge_datasets(dataframes[df_name], ppi_features_df)\n",
    "\n",
    "# Access each dataframe using its name\n",
    "train_fold1_df = dataframes['train_fold1_df']\n",
    "train_fold2_df = dataframes['train_fold2_df']\n",
    "train_fold3_df = dataframes['train_fold3_df']\n",
    "train_fold4_df = dataframes['train_fold4_df']\n",
    "train_fold5_df = dataframes['train_fold5_df']\n",
    "test_fold1_df = dataframes['test_fold1_df']\n",
    "test_fold2_df = dataframes['test_fold2_df']\n",
    "test_fold3_df = dataframes['test_fold3_df']\n",
    "test_fold4_df = dataframes['test_fold4_df']\n",
    "test_fold5_df = dataframes['test_fold5_df']\n",
    "\n",
    "PRINTM(f'Done inverse mapping & merging successfully !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0197c469-d6b0-4966-ad51-703dcf96f036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>label</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_6549_id2</th>\n",
       "      <th>Feature_6550_id2</th>\n",
       "      <th>Feature_6551_id2</th>\n",
       "      <th>Feature_6552_id2</th>\n",
       "      <th>Feature_6553_id2</th>\n",
       "      <th>Feature_6554_id2</th>\n",
       "      <th>Feature_6555_id2</th>\n",
       "      <th>Feature_6556_id2</th>\n",
       "      <th>Feature_6557_id2</th>\n",
       "      <th>Feature_6558_id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COc1ccc2c(c1)N(CCO)C1=C(C(=O)OC1)C2c1ccccc1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119173</td>\n",
       "      <td>0.192963</td>\n",
       "      <td>0.350809</td>\n",
       "      <td>-0.281154</td>\n",
       "      <td>-0.223251</td>\n",
       "      <td>0.110585</td>\n",
       "      <td>0.646323</td>\n",
       "      <td>-0.672050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158758</td>\n",
       "      <td>1.097417</td>\n",
       "      <td>0.005888</td>\n",
       "      <td>0.978788</td>\n",
       "      <td>-0.675368</td>\n",
       "      <td>0.950588</td>\n",
       "      <td>0.096819</td>\n",
       "      <td>0.05284</td>\n",
       "      <td>-0.147850</td>\n",
       "      <td>-0.440759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COc1cccc2c1C1=C(C(c3ccc(Br)cc3)O2)C(c2ccc(Br)c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119173</td>\n",
       "      <td>0.192963</td>\n",
       "      <td>0.350809</td>\n",
       "      <td>-0.281154</td>\n",
       "      <td>-0.223251</td>\n",
       "      <td>0.110585</td>\n",
       "      <td>0.646323</td>\n",
       "      <td>-0.672050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158758</td>\n",
       "      <td>1.097417</td>\n",
       "      <td>0.005888</td>\n",
       "      <td>0.978788</td>\n",
       "      <td>-0.675368</td>\n",
       "      <td>0.950588</td>\n",
       "      <td>0.096819</td>\n",
       "      <td>0.05284</td>\n",
       "      <td>-0.147850</td>\n",
       "      <td>-0.440759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C[C@H]1NC(=O)[C@H](CCCCNC(=O)CCCCCNC(=O)[C@H](...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028363</td>\n",
       "      <td>0.070038</td>\n",
       "      <td>-0.646506</td>\n",
       "      <td>-0.664209</td>\n",
       "      <td>-0.366271</td>\n",
       "      <td>0.133451</td>\n",
       "      <td>-0.779246</td>\n",
       "      <td>-1.016724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744427</td>\n",
       "      <td>-0.513272</td>\n",
       "      <td>0.160667</td>\n",
       "      <td>-0.751537</td>\n",
       "      <td>-0.724242</td>\n",
       "      <td>-0.446348</td>\n",
       "      <td>0.948117</td>\n",
       "      <td>0.53119</td>\n",
       "      <td>-1.448598</td>\n",
       "      <td>-0.337839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCCCC[C@H](N)C(=O)NCC(=O)N[C@@H](Cc1ccc(O)cc1)...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028363</td>\n",
       "      <td>0.070038</td>\n",
       "      <td>-0.646506</td>\n",
       "      <td>-0.664209</td>\n",
       "      <td>-0.366271</td>\n",
       "      <td>0.133451</td>\n",
       "      <td>-0.779246</td>\n",
       "      <td>-1.016724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744427</td>\n",
       "      <td>-0.513272</td>\n",
       "      <td>0.160667</td>\n",
       "      <td>-0.751537</td>\n",
       "      <td>-0.724242</td>\n",
       "      <td>-0.446348</td>\n",
       "      <td>0.948117</td>\n",
       "      <td>0.53119</td>\n",
       "      <td>-1.448598</td>\n",
       "      <td>-0.337839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCCCC[C@H](N)C(=O)NCC(=O)N[C@@H](Cc1ccc(O)cc1)...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028363</td>\n",
       "      <td>0.070038</td>\n",
       "      <td>-0.646506</td>\n",
       "      <td>-0.664209</td>\n",
       "      <td>-0.366271</td>\n",
       "      <td>0.133451</td>\n",
       "      <td>-0.779246</td>\n",
       "      <td>-1.016724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744427</td>\n",
       "      <td>-0.513272</td>\n",
       "      <td>0.160667</td>\n",
       "      <td>-0.751537</td>\n",
       "      <td>-0.724242</td>\n",
       "      <td>-0.446348</td>\n",
       "      <td>0.948117</td>\n",
       "      <td>0.53119</td>\n",
       "      <td>-1.448598</td>\n",
       "      <td>-0.337839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  label  Feature_1  \\\n",
       "0        COc1ccc2c(c1)N(CCO)C1=C(C(=O)OC1)C2c1ccccc1      1   0.119173   \n",
       "1  COc1cccc2c1C1=C(C(c3ccc(Br)cc3)O2)C(c2ccc(Br)c...      0   0.119173   \n",
       "2  C[C@H]1NC(=O)[C@H](CCCCNC(=O)CCCCCNC(=O)[C@H](...      1   0.028363   \n",
       "3  NCCCC[C@H](N)C(=O)NCC(=O)N[C@@H](Cc1ccc(O)cc1)...      1   0.028363   \n",
       "4  NCCCC[C@H](N)C(=O)NCC(=O)N[C@@H](Cc1ccc(O)cc1)...      1   0.028363   \n",
       "\n",
       "   Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  Feature_7  \\\n",
       "0   0.192963   0.350809  -0.281154  -0.223251   0.110585   0.646323   \n",
       "1   0.192963   0.350809  -0.281154  -0.223251   0.110585   0.646323   \n",
       "2   0.070038  -0.646506  -0.664209  -0.366271   0.133451  -0.779246   \n",
       "3   0.070038  -0.646506  -0.664209  -0.366271   0.133451  -0.779246   \n",
       "4   0.070038  -0.646506  -0.664209  -0.366271   0.133451  -0.779246   \n",
       "\n",
       "   Feature_8  ...  Feature_6549_id2  Feature_6550_id2  Feature_6551_id2  \\\n",
       "0  -0.672050  ...         -0.158758          1.097417          0.005888   \n",
       "1  -0.672050  ...         -0.158758          1.097417          0.005888   \n",
       "2  -1.016724  ...          0.744427         -0.513272          0.160667   \n",
       "3  -1.016724  ...          0.744427         -0.513272          0.160667   \n",
       "4  -1.016724  ...          0.744427         -0.513272          0.160667   \n",
       "\n",
       "   Feature_6552_id2  Feature_6553_id2  Feature_6554_id2  Feature_6555_id2  \\\n",
       "0          0.978788         -0.675368          0.950588          0.096819   \n",
       "1          0.978788         -0.675368          0.950588          0.096819   \n",
       "2         -0.751537         -0.724242         -0.446348          0.948117   \n",
       "3         -0.751537         -0.724242         -0.446348          0.948117   \n",
       "4         -0.751537         -0.724242         -0.446348          0.948117   \n",
       "\n",
       "   Feature_6556_id2  Feature_6557_id2  Feature_6558_id2  \n",
       "0           0.05284         -0.147850         -0.440759  \n",
       "1           0.05284         -0.147850         -0.440759  \n",
       "2           0.53119         -1.448598         -0.337839  \n",
       "3           0.53119         -1.448598         -0.337839  \n",
       "4           0.53119         -1.448598         -0.337839  \n",
       "\n",
       "[5 rows x 13118 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fold2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5229e465-72f6-4363-80bb-2c89dc1dfa01",
   "metadata": {},
   "source": [
    "#### Data Cleaning ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e85c1-93d7-485b-81c2-a7075969bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in dataframes.items():\n",
    "    null_counts = df.isnull().sum().sum()\n",
    "    PRINTM(f'Number of nan values in {df_name} is -> {null_counts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cda3362-a78e-41b0-b479-8d59641103f3",
   "metadata": {},
   "source": [
    "### Train a Model on Each Fold ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "433c42da-8de4-4673-9e17-5517a4ed2bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_val_datasets(df, portion) -> (pd.DataFrame, pd.DataFrame):\n",
    "    train_size = int(portion * len(df))\n",
    "    val_size = len(df) - train_size\n",
    "    train_data, val_data = train_test_split(df, test_size=val_size)\n",
    "    return (train_data, val_data)\n",
    "\n",
    "def generate_dataloaders(train_data, val_data,\n",
    "                         test_data, batch_size, shuffle):\n",
    "    train_dataset = MoleculeDataset(train_data)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    val_dataset = MoleculeDataset(val_data)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    test_dataset = MoleculeDataset(test_data)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return (train_loader, val_loader, test_loader)\n",
    "\n",
    "def generate_model(checkpoint_path,\n",
    "                   batch_size,\n",
    "                  dropout) -> nn.Module:\n",
    "    pretrained_chemprop_model = PretrainedChempropModel(checkpoints_path, batch_size)\n",
    "    chemberta_model = ChemBERTaPT()\n",
    "    ft_model = AUVG_PPI(pretrained_chemprop_model, chemberta_model, dropout).to(device)\n",
    "\n",
    "    PRINTM('Generated combined model for fine-tuning successfully !')\n",
    "    return ft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "670cbc2d-b20b-4e61-99e2-58e6a56d5e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = os.path.join('pt_chemprop_checkpoint', 'fold_0', 'model_0', 'checkpoints', 'best-epoch=49-val_loss=0.12.ckpt')\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa8a8b-2663-4240-9308-bd7add830b46",
   "metadata": {},
   "source": [
    "#### Fold number 1 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af29201-5e65-4924-9354-8abf1710ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f1 = generate_model(checkpoints_path, batch_size=32, dropout=0.1)\n",
    "f1_res = ft_model_f1.cross_validate(train_fold1_df, num_folds=10, num_epochs=3,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-5,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "495a4ff0-0bdd-4fbf-8cb3-24e8d229fd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.80260\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f1.test_model(test_fold1_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647d02d-7015-4a97-bf00-97d21dfa27fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f2 = generate_model(checkpoints_path, batch_size=32, dropout=0.8)\n",
    "f2_res = ft_model_f2.cross_validate(train_fold2_df, num_folds=10, num_epochs=3,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-3,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "521894c8-573d-4f23-829f-cf8731382b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.80285\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f2.test_model(test_fold2_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6178d88-b2c8-4573-8e0b-3739ae1fe750",
   "metadata": {},
   "source": [
    "#### Fold number 3 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eca39e-ac59-4b99-98f2-4b6172a4b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f3 = generate_model(checkpoints_path, batch_size=32, dropout=0.8)\n",
    "f3_res = ft_model_f3.cross_validate(train_fold3_df, num_folds=10, num_epochs=3,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-3,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784b5ef0-d53c-4f77-9d6c-93d9baea03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f3.test_model(test_fold3_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6468a6-6d67-46b9-bf81-b5ffdaae7f55",
   "metadata": {},
   "source": [
    "#### Folder number 4 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f586ef7-e04a-48de-a901-174d2d7b196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f4 = generate_model(checkpoints_path, batch_size=32, dropout=0.1)\n",
    "f4_res = ft_model_f4.cross_validate(train_fold4_df, num_folds=10, num_epochs=3,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-5,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f7452-6336-4a0b-849b-55636a4ae2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f4.test_model(test_fold4_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1be051e-278d-4bd3-b8e2-d90098292394",
   "metadata": {},
   "source": [
    "#### Folder number 5 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa2172-1e43-46ac-86af-bf5461820436",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f5 = generate_model(checkpoints_path, batch_size=32, dropout=0.8)\n",
    "f5_res = ft_model_f5.cross_validate(train_fold5_df, num_folds=10, num_epochs=3,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-3,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8480ac40-4eee-407a-b1f0-498a878b4e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f5.test_model(test_fold5_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd02b8-4df1-4dd8-9b89-73b4a23933d1",
   "metadata": {},
   "source": [
    "## Train the Model on Finetuned Datasets (DLIP_folds_2_0.8)  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "318521e6-2548-4430-9b13-331d0d3d1292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Folder content:\n",
      "\n",
      "['test_fold5.csv', 'test_fold2.csv', 'test_fold4.csv', 'test_fold3.csv', 'test_fold1.csv', 'train_fold4.csv', 'train_fold2.csv', 'train_fold3.csv', 'train_fold1.csv', 'train_fold5.csv']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ds_folder_path = os.path.join('datasets', 'finetune_dataset', 'DLIP_folds_2_0.8')\n",
    "all_files = os.listdir(ds_folder_path)\n",
    "\n",
    "PRINTM(f'Folder content:\\n\\n{all_files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc4dc475-61cf-4ff8-bc04-be92905c86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "\n",
    "# Read each CSV file into a dataframe and store it in the dictionary\n",
    "for file in all_files:\n",
    "    file_path = os.path.join(ds_folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_name = file.replace('.csv', '_df')\n",
    "    dataframes[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a6d1065-1ad7-49c9-bdb6-51acd8868dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Done inverse mapping & merging successfully !\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for df_name in dataframes.keys():\n",
    "    dataframes[df_name] = convert_uniprot_ids(dataframes[df_name], uniprot_mapping)\n",
    "    dataframes[df_name] = merge_datasets(dataframes[df_name], ppi_features_df)\n",
    "\n",
    "# Access each dataframe using its name\n",
    "train_fold1_df = dataframes['train_fold1_df']\n",
    "train_fold2_df = dataframes['train_fold2_df']\n",
    "train_fold3_df = dataframes['train_fold3_df']\n",
    "train_fold4_df = dataframes['train_fold4_df']\n",
    "train_fold5_df = dataframes['train_fold5_df']\n",
    "test_fold1_df = dataframes['test_fold1_df']\n",
    "test_fold2_df = dataframes['test_fold2_df']\n",
    "test_fold3_df = dataframes['test_fold3_df']\n",
    "test_fold4_df = dataframes['test_fold4_df']\n",
    "test_fold5_df = dataframes['test_fold5_df']\n",
    "\n",
    "PRINTM(f'Done inverse mapping & merging successfully !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ac6fd3-2976-4cf2-bc63-0475648caaff",
   "metadata": {},
   "source": [
    "#### Fold number 1 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "281a6ec4-05f8-4771-bf99-8aff7276d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1124747-606d-4c49-9685-541b9f2751df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f1_dlip = generate_model(checkpoints_path, batch_size=32, dropout=0.1)\n",
    "f1_dlip_res = ft_model_f1_dlip.cross_validate(train_fold1_df, num_folds=10, num_epochs=3,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-5,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3fd55f1f-a88f-4975-87b9-35cfb767b4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.56891\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f1_dlip.test_model(test_fold1_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cabbfb-3583-4d68-ad53-3b0debe06b75",
   "metadata": {},
   "source": [
    "#### Fold number 2 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e631bb1b-af66-465d-b757-84b0b7235017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>label</th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_1270_id2</th>\n",
       "      <th>Feature_1271_id2</th>\n",
       "      <th>Feature_1272_id2</th>\n",
       "      <th>Feature_1273_id2</th>\n",
       "      <th>Feature_1274_id2</th>\n",
       "      <th>Feature_1275_id2</th>\n",
       "      <th>Feature_1276_id2</th>\n",
       "      <th>Feature_1277_id2</th>\n",
       "      <th>Feature_1278_id2</th>\n",
       "      <th>Feature_1279_id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC1(C)Cc2c(C#N)c(SCC(=O)c3ccccc3)nc(N3CCOCC3)c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024904</td>\n",
       "      <td>-0.016439</td>\n",
       "      <td>-0.036580</td>\n",
       "      <td>0.103679</td>\n",
       "      <td>-0.033915</td>\n",
       "      <td>-0.088769</td>\n",
       "      <td>0.110536</td>\n",
       "      <td>0.021462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>0.015843</td>\n",
       "      <td>-0.125636</td>\n",
       "      <td>0.085471</td>\n",
       "      <td>0.052038</td>\n",
       "      <td>0.012726</td>\n",
       "      <td>0.042278</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>0.056452</td>\n",
       "      <td>0.055316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC(C)c1cc(-c2cc3ccccc3nc2N2CCCC2)cc2nc(N3CCCC3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016134</td>\n",
       "      <td>-0.060721</td>\n",
       "      <td>-0.051823</td>\n",
       "      <td>0.028336</td>\n",
       "      <td>-0.062652</td>\n",
       "      <td>-0.053298</td>\n",
       "      <td>0.085150</td>\n",
       "      <td>-0.030032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046108</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>-0.160452</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>-0.045173</td>\n",
       "      <td>-0.135907</td>\n",
       "      <td>0.036617</td>\n",
       "      <td>-0.136259</td>\n",
       "      <td>-0.023708</td>\n",
       "      <td>0.164988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C[C@H](NC(=O)OCc1ccccc1)C(=O)NCC(=O)N[C@@H](CC...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>-0.022420</td>\n",
       "      <td>0.022537</td>\n",
       "      <td>0.068212</td>\n",
       "      <td>0.013745</td>\n",
       "      <td>-0.050679</td>\n",
       "      <td>0.050013</td>\n",
       "      <td>0.029418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>-0.041317</td>\n",
       "      <td>-0.155951</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.038189</td>\n",
       "      <td>-0.007605</td>\n",
       "      <td>0.050163</td>\n",
       "      <td>-0.057858</td>\n",
       "      <td>0.035910</td>\n",
       "      <td>0.098834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCCOc1nc2ccccc2cc1-c1cc(C(C)C)c2ccc(N3CCOCC3)n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010813</td>\n",
       "      <td>0.013121</td>\n",
       "      <td>0.010302</td>\n",
       "      <td>0.080439</td>\n",
       "      <td>-0.059494</td>\n",
       "      <td>-0.098062</td>\n",
       "      <td>0.065032</td>\n",
       "      <td>0.091731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022349</td>\n",
       "      <td>0.037069</td>\n",
       "      <td>-0.190583</td>\n",
       "      <td>-0.007384</td>\n",
       "      <td>-0.006035</td>\n",
       "      <td>-0.031601</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>-0.060644</td>\n",
       "      <td>0.106156</td>\n",
       "      <td>0.101168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=C(O)CCNC(=O)[C@H](c1ccc(Cl)cc1)N1C(=O)c2cc(I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019827</td>\n",
       "      <td>-0.132773</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.141837</td>\n",
       "      <td>-0.097555</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.215369</td>\n",
       "      <td>-0.009062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055858</td>\n",
       "      <td>0.055593</td>\n",
       "      <td>-0.091637</td>\n",
       "      <td>0.041687</td>\n",
       "      <td>-0.016587</td>\n",
       "      <td>-0.035697</td>\n",
       "      <td>0.025542</td>\n",
       "      <td>-0.037288</td>\n",
       "      <td>0.011203</td>\n",
       "      <td>0.017735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  label  Feature_0  \\\n",
       "0  CC1(C)Cc2c(C#N)c(SCC(=O)c3ccccc3)nc(N3CCOCC3)c...      0   0.024904   \n",
       "1  CC(C)c1cc(-c2cc3ccccc3nc2N2CCCC2)cc2nc(N3CCCC3...      0   0.016134   \n",
       "2  C[C@H](NC(=O)OCc1ccccc1)C(=O)NCC(=O)N[C@@H](CC...      1   0.027740   \n",
       "3  CCCOc1nc2ccccc2cc1-c1cc(C(C)C)c2ccc(N3CCOCC3)n...      0   0.010813   \n",
       "4  O=C(O)CCNC(=O)[C@H](c1ccc(Cl)cc1)N1C(=O)c2cc(I...      0   0.019827   \n",
       "\n",
       "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0  -0.016439  -0.036580   0.103679  -0.033915  -0.088769   0.110536   \n",
       "1  -0.060721  -0.051823   0.028336  -0.062652  -0.053298   0.085150   \n",
       "2  -0.022420   0.022537   0.068212   0.013745  -0.050679   0.050013   \n",
       "3   0.013121   0.010302   0.080439  -0.059494  -0.098062   0.065032   \n",
       "4  -0.132773  -0.000028   0.141837  -0.097555   0.025639   0.215369   \n",
       "\n",
       "   Feature_7  ...  Feature_1270_id2  Feature_1271_id2  Feature_1272_id2  \\\n",
       "0   0.021462  ...          0.008593          0.015843         -0.125636   \n",
       "1  -0.030032  ...         -0.046108          0.018945         -0.160452   \n",
       "2   0.029418  ...          0.002036         -0.041317         -0.155951   \n",
       "3   0.091731  ...          0.022349          0.037069         -0.190583   \n",
       "4  -0.009062  ...          0.055858          0.055593         -0.091637   \n",
       "\n",
       "   Feature_1273_id2  Feature_1274_id2  Feature_1275_id2  Feature_1276_id2  \\\n",
       "0          0.085471          0.052038          0.012726          0.042278   \n",
       "1          0.058708         -0.045173         -0.135907          0.036617   \n",
       "2          0.003789          0.038189         -0.007605          0.050163   \n",
       "3         -0.007384         -0.006035         -0.031601          0.002871   \n",
       "4          0.041687         -0.016587         -0.035697          0.025542   \n",
       "\n",
       "   Feature_1277_id2  Feature_1278_id2  Feature_1279_id2  \n",
       "0         -0.091071          0.056452          0.055316  \n",
       "1         -0.136259         -0.023708          0.164988  \n",
       "2         -0.057858          0.035910          0.098834  \n",
       "3         -0.060644          0.106156          0.101168  \n",
       "4         -0.037288          0.011203          0.017735  \n",
       "\n",
       "[5 rows x 2562 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fold2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158a226-7267-47eb-b3f5-5ad98cff73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f2_dlip = generate_model(checkpoints_path, batch_size=32, dropout=0.1)\n",
    "f2_dlip_res = ft_model_f2_dlip.cross_validate(train_fold2_df, num_folds=10, num_epochs=5,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-5,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616ed377-91a9-4774-9fe6-d5c83d310116",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f2_dlip.test_model(test_fold2_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e549c4-121c-49b9-9dc6-912d332a07cc",
   "metadata": {},
   "source": [
    "#### Fold number 3 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8edb3-3b96-415f-ac39-47cd6c608f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f3_dlip = generate_model(checkpoints_path, batch_size=32, dropout=0.1)\n",
    "f3_dlip_res = ft_model_f3_dlip.cross_validate(train_fold3_df, num_folds=10, num_epochs=5,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-5,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bf64088-2c47-42ec-9bab-acd78a2646d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.77997\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f3_dlip.test_model(test_fold3_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482b84d6-2a20-41ea-89fd-4f39bc7a0f6d",
   "metadata": {},
   "source": [
    "#### Fold number 4 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574efb2-3727-4238-8104-90f333c3cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f4_dlip = generate_model(checkpoints_path, batch_size=32, dropout=0.1)\n",
    "f4_dlip_res = ft_model_f4_dlip.cross_validate(train_fold4_df, num_folds=10, num_epochs=5,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-5,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9d9d0ef-dd3e-4101-8725-bffc49956819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.86750\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f4_dlip.test_model(test_fold4_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2730dc6-8a20-4aae-b2dc-1608793f8c1f",
   "metadata": {},
   "source": [
    "#### Fold number 5 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462432a-a49c-4829-814d-44fcdd0d7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f5_dlip = generate_model(checkpoints_path, batch_size=32, dropout=0.1)\n",
    "f5_dlip_res = ft_model_f5_dlip.cross_validate(train_fold5_df, num_folds=10, num_epochs=5,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-5,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d5e5d22-315a-4193-b54c-b60abfa38bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.80413\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f5_dlip.test_model(test_fold5_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e471e7f4-7d04-4aa1-83cf-464dcc518d1b",
   "metadata": {},
   "source": [
    "## Train the Model on Finetuned Datasets (DLIP_folds_2_0.9)  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed08be16-4937-44bc-8cb9-8f8e7aed2b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Folder content:\n",
      "\n",
      "['test_fold3.csv', 'test_fold2.csv', 'test_fold1.csv', 'test_fold5.csv', 'train_fold4.csv', 'train_fold2.csv', 'train_fold3.csv', 'train_fold5.csv', 'test_fold4.csv', 'train_fold1.csv']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ds_folder_path = os.path.join('datasets', 'finetune_dataset', 'DLIP_folds_3_0.9')\n",
    "all_files = os.listdir(ds_folder_path)\n",
    "\n",
    "PRINTM(f'Folder content:\\n\\n{all_files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b684433-0cfb-4372-85ea-3ed8eb5f59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "\n",
    "# Read each CSV file into a dataframe and store it in the dictionary\n",
    "for file in all_files:\n",
    "    file_path = os.path.join(ds_folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_name = file.replace('.csv', '_df')\n",
    "    dataframes[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4550d26-8036-4f0f-89a5-a25e17d0efa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Done inverse mapping & merging successfully !\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for df_name in dataframes.keys():\n",
    "    dataframes[df_name] = convert_uniprot_ids(dataframes[df_name], uniprot_mapping)\n",
    "    dataframes[df_name] = merge_datasets(dataframes[df_name], ppi_features_df)\n",
    "\n",
    "# Access each dataframe using its name\n",
    "train_fold1_df = dataframes['train_fold1_df']\n",
    "train_fold2_df = dataframes['train_fold2_df']\n",
    "train_fold3_df = dataframes['train_fold3_df']\n",
    "train_fold4_df = dataframes['train_fold4_df']\n",
    "train_fold5_df = dataframes['train_fold5_df']\n",
    "test_fold1_df = dataframes['test_fold1_df']\n",
    "test_fold2_df = dataframes['test_fold2_df']\n",
    "test_fold3_df = dataframes['test_fold3_df']\n",
    "test_fold4_df = dataframes['test_fold4_df']\n",
    "test_fold5_df = dataframes['test_fold5_df']\n",
    "\n",
    "PRINTM(f'Done inverse mapping & merging successfully !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce778512-32a9-456a-81f3-d81de40a27cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>label</th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_1270_id2</th>\n",
       "      <th>Feature_1271_id2</th>\n",
       "      <th>Feature_1272_id2</th>\n",
       "      <th>Feature_1273_id2</th>\n",
       "      <th>Feature_1274_id2</th>\n",
       "      <th>Feature_1275_id2</th>\n",
       "      <th>Feature_1276_id2</th>\n",
       "      <th>Feature_1277_id2</th>\n",
       "      <th>Feature_1278_id2</th>\n",
       "      <th>Feature_1279_id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nc1ccc(CNC(=O)NC[C@H](NC(=O)[C@@H]2CCCN2S(=O)(...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>-0.068394</td>\n",
       "      <td>-0.093040</td>\n",
       "      <td>0.142344</td>\n",
       "      <td>-0.101274</td>\n",
       "      <td>-0.057618</td>\n",
       "      <td>0.093081</td>\n",
       "      <td>-0.037972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052764</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>-0.032889</td>\n",
       "      <td>0.013346</td>\n",
       "      <td>-0.002336</td>\n",
       "      <td>-0.061765</td>\n",
       "      <td>0.122240</td>\n",
       "      <td>-0.107535</td>\n",
       "      <td>-0.056424</td>\n",
       "      <td>0.064282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C(O)CCNC(=O)c1ccc2c(c1)C(=O)N(CCC1CCNCC1)C2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>-0.068394</td>\n",
       "      <td>-0.093040</td>\n",
       "      <td>0.142344</td>\n",
       "      <td>-0.101274</td>\n",
       "      <td>-0.057618</td>\n",
       "      <td>0.093081</td>\n",
       "      <td>-0.037972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046108</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>-0.160452</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>-0.045173</td>\n",
       "      <td>-0.135907</td>\n",
       "      <td>0.036617</td>\n",
       "      <td>-0.136259</td>\n",
       "      <td>-0.023708</td>\n",
       "      <td>0.164988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cc1cc(C)cc(S(=O)(=O)N2CCC[C@H]2C(=O)N[C@@H](CN...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>-0.068394</td>\n",
       "      <td>-0.093040</td>\n",
       "      <td>0.142344</td>\n",
       "      <td>-0.101274</td>\n",
       "      <td>-0.057618</td>\n",
       "      <td>0.093081</td>\n",
       "      <td>-0.037972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052764</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>-0.032889</td>\n",
       "      <td>0.013346</td>\n",
       "      <td>-0.002336</td>\n",
       "      <td>-0.061765</td>\n",
       "      <td>0.122240</td>\n",
       "      <td>-0.107535</td>\n",
       "      <td>-0.056424</td>\n",
       "      <td>0.064282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O=C(O)CC(NC(=O)CCC(=O)Nc1ccc2c(c1)CNC2)c1ccccc1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013775</td>\n",
       "      <td>-0.061126</td>\n",
       "      <td>-0.020618</td>\n",
       "      <td>0.032968</td>\n",
       "      <td>-0.081779</td>\n",
       "      <td>-0.046594</td>\n",
       "      <td>0.086232</td>\n",
       "      <td>-0.010491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046108</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>-0.160452</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>-0.045173</td>\n",
       "      <td>-0.135907</td>\n",
       "      <td>0.036617</td>\n",
       "      <td>-0.136259</td>\n",
       "      <td>-0.023708</td>\n",
       "      <td>0.164988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N=C(N)NCCC[C@@H]1NC(=O)[C@H]2COCCN2C(=O)[C@@H]...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016134</td>\n",
       "      <td>-0.060721</td>\n",
       "      <td>-0.051823</td>\n",
       "      <td>0.028336</td>\n",
       "      <td>-0.062652</td>\n",
       "      <td>-0.053298</td>\n",
       "      <td>0.085150</td>\n",
       "      <td>-0.030032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036552</td>\n",
       "      <td>-0.016408</td>\n",
       "      <td>-0.189185</td>\n",
       "      <td>0.029432</td>\n",
       "      <td>-0.061862</td>\n",
       "      <td>-0.075560</td>\n",
       "      <td>0.090893</td>\n",
       "      <td>-0.115112</td>\n",
       "      <td>-0.029084</td>\n",
       "      <td>0.098593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  label  Feature_0  \\\n",
       "0  Nc1ccc(CNC(=O)NC[C@H](NC(=O)[C@@H]2CCCN2S(=O)(...      1   0.030220   \n",
       "1      O=C(O)CCNC(=O)c1ccc2c(c1)C(=O)N(CCC1CCNCC1)C2      1   0.030220   \n",
       "2  Cc1cc(C)cc(S(=O)(=O)N2CCC[C@H]2C(=O)N[C@@H](CN...      1   0.030220   \n",
       "3    O=C(O)CC(NC(=O)CCC(=O)Nc1ccc2c(c1)CNC2)c1ccccc1      1   0.013775   \n",
       "4  N=C(N)NCCC[C@@H]1NC(=O)[C@H]2COCCN2C(=O)[C@@H]...      1   0.016134   \n",
       "\n",
       "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0  -0.068394  -0.093040   0.142344  -0.101274  -0.057618   0.093081   \n",
       "1  -0.068394  -0.093040   0.142344  -0.101274  -0.057618   0.093081   \n",
       "2  -0.068394  -0.093040   0.142344  -0.101274  -0.057618   0.093081   \n",
       "3  -0.061126  -0.020618   0.032968  -0.081779  -0.046594   0.086232   \n",
       "4  -0.060721  -0.051823   0.028336  -0.062652  -0.053298   0.085150   \n",
       "\n",
       "   Feature_7  ...  Feature_1270_id2  Feature_1271_id2  Feature_1272_id2  \\\n",
       "0  -0.037972  ...          0.052764          0.007230         -0.032889   \n",
       "1  -0.037972  ...         -0.046108          0.018945         -0.160452   \n",
       "2  -0.037972  ...          0.052764          0.007230         -0.032889   \n",
       "3  -0.010491  ...         -0.046108          0.018945         -0.160452   \n",
       "4  -0.030032  ...         -0.036552         -0.016408         -0.189185   \n",
       "\n",
       "   Feature_1273_id2  Feature_1274_id2  Feature_1275_id2  Feature_1276_id2  \\\n",
       "0          0.013346         -0.002336         -0.061765          0.122240   \n",
       "1          0.058708         -0.045173         -0.135907          0.036617   \n",
       "2          0.013346         -0.002336         -0.061765          0.122240   \n",
       "3          0.058708         -0.045173         -0.135907          0.036617   \n",
       "4          0.029432         -0.061862         -0.075560          0.090893   \n",
       "\n",
       "   Feature_1277_id2  Feature_1278_id2  Feature_1279_id2  \n",
       "0         -0.107535         -0.056424          0.064282  \n",
       "1         -0.136259         -0.023708          0.164988  \n",
       "2         -0.107535         -0.056424          0.064282  \n",
       "3         -0.136259         -0.023708          0.164988  \n",
       "4         -0.115112         -0.029084          0.098593  \n",
       "\n",
       "[5 rows x 2562 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fold5_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed4596-78bf-4498-afc3-2d67f77a0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in dataframes.items():\n",
    "    null_counts = df.isnull().sum().sum()\n",
    "    PRINTM(f'Number of nan values in {df_name} is -> {null_counts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5674f908-229d-4d2c-b5ad-adb2efeccd05",
   "metadata": {},
   "source": [
    "#### Fold number 1 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b9a0431-028a-4665-93c6-145a2b7204c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e945c8a3-350b-4dc7-bc7f-d82a549f4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f1_dlip_ = generate_model(checkpoints_path, batch_size=64, dropout=0.8)\n",
    "f1_dlip_res = ft_model_f1_dlip_.cross_validate(train_fold1_df, num_folds=10, num_epochs=5,\n",
    "                     batch_size=64, learning_rate=0.0001, weight_decay=1e-4,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ddf1426-08fe-4388-ad58-57dfe17d6467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.38214\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f1_dlip_.test_model(test_fold1_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=64,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1950457-20d8-4d06-b138-87e76422f075",
   "metadata": {},
   "source": [
    "#### Fold number 2 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6223efa5-b615-4323-8d90-8b8fdd262219",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f2_dlip_ = generate_model(checkpoints_path, batch_size=64, dropout=0.3)\n",
    "f2_dlip_res_ = ft_model_f2_dlip_.cross_validate(train_fold2_df, num_folds=10, num_epochs=5,\n",
    "                     batch_size=64, learning_rate=0.0001, weight_decay=1e-4,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c73d38c-d8f5-4011-bcaf-9318de459680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.77614\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f2_dlip_.test_model(test_fold2_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=64,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a4cae1-687f-4857-a6fb-19ee8fc171ff",
   "metadata": {},
   "source": [
    "#### Fold number 3 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaea950-c333-486e-b77b-a9966c9fab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f3_dlip_ = generate_model(checkpoints_path, batch_size=64, dropout=0.3)\n",
    "f3_dlip_res_ = ft_model_f3_dlip_.cross_validate(train_fold3_df, num_folds=10, num_epochs=5,\n",
    "                     batch_size=64, learning_rate=0.0001, weight_decay=1e-4,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cee2c129-1d47-4065-b623-f46354c3dd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.71449\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f3_dlip_.test_model(test_fold3_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=64,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d5349-1e57-49a6-8eaf-323712777290",
   "metadata": {},
   "source": [
    "#### Fold number 4 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b69a3-7e51-429c-8b7d-28dd32915f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f4_dlip_ = generate_model(checkpoints_path, batch_size=64, dropout=0.3)\n",
    "f4_dlip_res_ = ft_model_f4_dlip_.cross_validate(train_fold4_df, num_folds=10, num_epochs=5,\n",
    "                     batch_size=64, learning_rate=0.0001, weight_decay=1e-4,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58fc5c63-9318-42fc-bcc2-840c542a7460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.84679\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f4_dlip_.test_model(test_fold4_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=64,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbef40d-2cc6-41d2-8db9-0f6fd57a1198",
   "metadata": {},
   "source": [
    "#### Fold number 5 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d950655-1ff6-43ac-bec6-7f49ac92d61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f5_dlip_ = generate_model(checkpoints_path, batch_size=64, dropout=0.3)\n",
    "f5_dlip_res_ = ft_model_f5_dlip_.cross_validate(train_fold5_df, num_folds=10, num_epochs=5,\n",
    "                     batch_size=64, learning_rate=0.0001, weight_decay=1e-4,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10931e24-a779-4da4-9c64-86b2171e37b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.83778\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f5_dlip_.test_model(test_fold5_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=64,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "391b1e51-0856-49c3-a0e5-c9234aa8d523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Folder content:\n",
      "\n",
      "['test_fold1.csv', 'test_fold3.csv', 'test_fold5.csv', 'train_val_fold2.csv', 'train_val_fold3.csv', 'train_val_fold5.csv', 'test_fold4.csv', 'train_val_fold4.csv', 'test_fold2.csv', 'train_val_fold1.csv']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ds_folder_path = os.path.join('datasets', 'finetune_dataset', 'original_folds PPIMI')\n",
    "all_files = os.listdir(ds_folder_path)\n",
    "\n",
    "PRINTM(f'Folder content:\\n\\n{all_files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f8faf93-90c8-4352-af3d-8e37b5daec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "\n",
    "# Read each CSV file into a dataframe and store it in the dictionary\n",
    "for file in all_files:\n",
    "    file_path = os.path.join(ds_folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_name = file.replace('.csv', '_df')\n",
    "    dataframes[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88655676-bee3-426f-9030-8ddcf28ba8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame: test_fold1_df\n",
      "Updated DataFrame: test_fold3_df\n",
      "Updated DataFrame: test_fold5_df\n",
      "Updated DataFrame: train_val_fold2_df\n",
      "Updated DataFrame: train_val_fold3_df\n",
      "Updated DataFrame: train_val_fold5_df\n",
      "Updated DataFrame: test_fold4_df\n",
      "Updated DataFrame: train_val_fold4_df\n",
      "Updated DataFrame: test_fold2_df\n",
      "Updated DataFrame: train_val_fold1_df\n"
     ]
    }
   ],
   "source": [
    "for df_name, df in dataframes.items():\n",
    "    # Replace 'na' with np.nan if necessary\n",
    "    df.replace('na', np.nan, inplace=True)\n",
    "    \n",
    "    # Identify rows where 'uniprot_id2' is NaN and replace them with 'uniprot_id1' values\n",
    "    df.loc[df['uniprot_id2'].isna(), 'uniprot_id2'] = df['uniprot_id1']\n",
    "    \n",
    "    print(f'Updated DataFrame: {df_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a709fd5-bafb-4fb0-9847-2be0d8e43d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>uniprot_id1</th>\n",
       "      <th>uniprot_id2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6305</th>\n",
       "      <td>COc1cnc2n1C(C)(Cc1ccc(Br)cc1)C(=O)N2c1cc(Cl)cc...</td>\n",
       "      <td>P62942</td>\n",
       "      <td>P62942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>COc1cccc2c(C(=O)C(=O)N3CCN(C(=O)c4ccccc4)CC3)c...</td>\n",
       "      <td>P62942</td>\n",
       "      <td>P62942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>COc1cc(-c2cn(C)c(=O)c3cnccc23)cc(OC)c1CN(C)C</td>\n",
       "      <td>P62942</td>\n",
       "      <td>P62942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>CC(C)c1ccccc1Sc1ccc(-c2ccnc(N3CCCC3)c2)cc1C(F)...</td>\n",
       "      <td>P62942</td>\n",
       "      <td>P62942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>CNc1cccc(CCOc2ccc(C[C@H](NC(=O)c3c(Cl)cncc3Cl)...</td>\n",
       "      <td>P62942</td>\n",
       "      <td>P62942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles uniprot_id1  \\\n",
       "6305  COc1cnc2n1C(C)(Cc1ccc(Br)cc1)C(=O)N2c1cc(Cl)cc...      P62942   \n",
       "6306  COc1cccc2c(C(=O)C(=O)N3CCN(C(=O)c4ccccc4)CC3)c...      P62942   \n",
       "6307       COc1cc(-c2cn(C)c(=O)c3cnccc23)cc(OC)c1CN(C)C      P62942   \n",
       "6308  CC(C)c1ccccc1Sc1ccc(-c2ccnc(N3CCCC3)c2)cc1C(F)...      P62942   \n",
       "6309  CNc1cccc(CCOc2ccc(C[C@H](NC(=O)c3c(Cl)cncc3Cl)...      P62942   \n",
       "\n",
       "     uniprot_id2  label  \n",
       "6305      P62942      0  \n",
       "6306      P62942      0  \n",
       "6307      P62942      0  \n",
       "6308      P62942      0  \n",
       "6309      P62942      0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fold5_df = dataframes['test_fold5_df']\n",
    "test_fold5_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7af288e3-c827-4ee2-8a7a-268e464ed6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Done inverse mapping & merging successfully !\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for df_name in dataframes.keys():\n",
    "    dataframes[df_name] = convert_uniprot_ids(dataframes[df_name], uniprot_mapping)\n",
    "    dataframes[df_name] = merge_datasets(dataframes[df_name], esm_df)\n",
    "\n",
    "# Access each dataframe using its name\n",
    "train_fold1_df = dataframes['train_val_fold1_df']\n",
    "train_fold2_df = dataframes['train_val_fold2_df']\n",
    "train_fold3_df = dataframes['train_val_fold3_df']\n",
    "train_fold4_df = dataframes['train_val_fold4_df']\n",
    "train_fold5_df = dataframes['train_val_fold5_df']\n",
    "test_fold1_df = dataframes['test_fold1_df']\n",
    "test_fold2_df = dataframes['test_fold2_df']\n",
    "test_fold3_df = dataframes['test_fold3_df']\n",
    "test_fold4_df = dataframes['test_fold4_df']\n",
    "test_fold5_df = dataframes['test_fold5_df']\n",
    "\n",
    "PRINTM(f'Done inverse mapping & merging successfully !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da7103b9-1be3-430a-8932-ed343b517dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>label</th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_1270_id2</th>\n",
       "      <th>Feature_1271_id2</th>\n",
       "      <th>Feature_1272_id2</th>\n",
       "      <th>Feature_1273_id2</th>\n",
       "      <th>Feature_1274_id2</th>\n",
       "      <th>Feature_1275_id2</th>\n",
       "      <th>Feature_1276_id2</th>\n",
       "      <th>Feature_1277_id2</th>\n",
       "      <th>Feature_1278_id2</th>\n",
       "      <th>Feature_1279_id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nc1ccc(CNC(=O)NC[C@H](NC(=O)[C@@H]2CCCN2S(=O)(...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>-0.068394</td>\n",
       "      <td>-0.093040</td>\n",
       "      <td>0.142344</td>\n",
       "      <td>-0.101274</td>\n",
       "      <td>-0.057618</td>\n",
       "      <td>0.093081</td>\n",
       "      <td>-0.037972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052764</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>-0.032889</td>\n",
       "      <td>0.013346</td>\n",
       "      <td>-0.002336</td>\n",
       "      <td>-0.061765</td>\n",
       "      <td>0.122240</td>\n",
       "      <td>-0.107535</td>\n",
       "      <td>-0.056424</td>\n",
       "      <td>0.064282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C(O)CCNC(=O)c1ccc2c(c1)C(=O)N(CCC1CCNCC1)C2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>-0.068394</td>\n",
       "      <td>-0.093040</td>\n",
       "      <td>0.142344</td>\n",
       "      <td>-0.101274</td>\n",
       "      <td>-0.057618</td>\n",
       "      <td>0.093081</td>\n",
       "      <td>-0.037972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046108</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>-0.160452</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>-0.045173</td>\n",
       "      <td>-0.135907</td>\n",
       "      <td>0.036617</td>\n",
       "      <td>-0.136259</td>\n",
       "      <td>-0.023708</td>\n",
       "      <td>0.164988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cc1cc(C)cc(S(=O)(=O)N2CCC[C@H]2C(=O)N[C@@H](CN...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>-0.068394</td>\n",
       "      <td>-0.093040</td>\n",
       "      <td>0.142344</td>\n",
       "      <td>-0.101274</td>\n",
       "      <td>-0.057618</td>\n",
       "      <td>0.093081</td>\n",
       "      <td>-0.037972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052764</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>-0.032889</td>\n",
       "      <td>0.013346</td>\n",
       "      <td>-0.002336</td>\n",
       "      <td>-0.061765</td>\n",
       "      <td>0.122240</td>\n",
       "      <td>-0.107535</td>\n",
       "      <td>-0.056424</td>\n",
       "      <td>0.064282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O=C(O)CC(NC(=O)CCC(=O)Nc1ccc2c(c1)CNC2)c1ccccc1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013775</td>\n",
       "      <td>-0.061126</td>\n",
       "      <td>-0.020618</td>\n",
       "      <td>0.032968</td>\n",
       "      <td>-0.081779</td>\n",
       "      <td>-0.046594</td>\n",
       "      <td>0.086232</td>\n",
       "      <td>-0.010491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046108</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>-0.160452</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>-0.045173</td>\n",
       "      <td>-0.135907</td>\n",
       "      <td>0.036617</td>\n",
       "      <td>-0.136259</td>\n",
       "      <td>-0.023708</td>\n",
       "      <td>0.164988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N=C(N)NCCC[C@@H]1NC(=O)[C@H]2COCCN2C(=O)[C@@H]...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016134</td>\n",
       "      <td>-0.060721</td>\n",
       "      <td>-0.051823</td>\n",
       "      <td>0.028336</td>\n",
       "      <td>-0.062652</td>\n",
       "      <td>-0.053298</td>\n",
       "      <td>0.085150</td>\n",
       "      <td>-0.030032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036552</td>\n",
       "      <td>-0.016408</td>\n",
       "      <td>-0.189185</td>\n",
       "      <td>0.029432</td>\n",
       "      <td>-0.061862</td>\n",
       "      <td>-0.075560</td>\n",
       "      <td>0.090893</td>\n",
       "      <td>-0.115112</td>\n",
       "      <td>-0.029084</td>\n",
       "      <td>0.098593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  label  Feature_0  \\\n",
       "0  Nc1ccc(CNC(=O)NC[C@H](NC(=O)[C@@H]2CCCN2S(=O)(...      1   0.030220   \n",
       "1      O=C(O)CCNC(=O)c1ccc2c(c1)C(=O)N(CCC1CCNCC1)C2      1   0.030220   \n",
       "2  Cc1cc(C)cc(S(=O)(=O)N2CCC[C@H]2C(=O)N[C@@H](CN...      1   0.030220   \n",
       "3    O=C(O)CC(NC(=O)CCC(=O)Nc1ccc2c(c1)CNC2)c1ccccc1      1   0.013775   \n",
       "4  N=C(N)NCCC[C@@H]1NC(=O)[C@H]2COCCN2C(=O)[C@@H]...      1   0.016134   \n",
       "\n",
       "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0  -0.068394  -0.093040   0.142344  -0.101274  -0.057618   0.093081   \n",
       "1  -0.068394  -0.093040   0.142344  -0.101274  -0.057618   0.093081   \n",
       "2  -0.068394  -0.093040   0.142344  -0.101274  -0.057618   0.093081   \n",
       "3  -0.061126  -0.020618   0.032968  -0.081779  -0.046594   0.086232   \n",
       "4  -0.060721  -0.051823   0.028336  -0.062652  -0.053298   0.085150   \n",
       "\n",
       "   Feature_7  ...  Feature_1270_id2  Feature_1271_id2  Feature_1272_id2  \\\n",
       "0  -0.037972  ...          0.052764          0.007230         -0.032889   \n",
       "1  -0.037972  ...         -0.046108          0.018945         -0.160452   \n",
       "2  -0.037972  ...          0.052764          0.007230         -0.032889   \n",
       "3  -0.010491  ...         -0.046108          0.018945         -0.160452   \n",
       "4  -0.030032  ...         -0.036552         -0.016408         -0.189185   \n",
       "\n",
       "   Feature_1273_id2  Feature_1274_id2  Feature_1275_id2  Feature_1276_id2  \\\n",
       "0          0.013346         -0.002336         -0.061765          0.122240   \n",
       "1          0.058708         -0.045173         -0.135907          0.036617   \n",
       "2          0.013346         -0.002336         -0.061765          0.122240   \n",
       "3          0.058708         -0.045173         -0.135907          0.036617   \n",
       "4          0.029432         -0.061862         -0.075560          0.090893   \n",
       "\n",
       "   Feature_1277_id2  Feature_1278_id2  Feature_1279_id2  \n",
       "0         -0.107535         -0.056424          0.064282  \n",
       "1         -0.136259         -0.023708          0.164988  \n",
       "2         -0.107535         -0.056424          0.064282  \n",
       "3         -0.136259         -0.023708          0.164988  \n",
       "4         -0.115112         -0.029084          0.098593  \n",
       "\n",
       "[5 rows x 2562 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fold5_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1b68809-ab1e-49ef-902e-9dee2c145dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Number of nan values in test_fold1_df is -> 0\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Number of nan values in test_fold3_df is -> 0\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Number of nan values in test_fold5_df is -> 0\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Number of nan values in train_val_fold2_df is -> 0\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Number of nan values in train_val_fold3_df is -> 0\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Number of nan values in train_val_fold5_df is -> 0\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Number of nan values in test_fold4_df is -> 0\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Number of nan values in train_val_fold4_df is -> 0\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Number of nan values in test_fold2_df is -> 0\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Number of nan values in train_val_fold1_df is -> 0\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for df_name, df in dataframes.items():\n",
    "    null_counts = df.isnull().sum().sum()\n",
    "    PRINTM(f'Number of nan values in {df_name} is -> {null_counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2a2e2594-732d-46c9-8eef-8f0043d95050",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e0dcf-d2f0-4e23-b5ab-1ec60d422d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f1 = generate_model(checkpoints_path, batch_size=32, dropout=0.5)\n",
    "f1_res = ft_model_f1.cross_validate(train_fold1_df, num_folds=5, num_epochs=10,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-5,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e34b79d5-4961-48c4-a65d-1e647725bd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test BCELoss: 4.62058\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test Accuracy: 0.52\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.53026\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f1.test_model(test_fold1_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac3d16-15a7-441d-b2e0-5a1db910e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f2 = generate_model(checkpoints_path, batch_size=32, dropout=0.5)\n",
    "f2_res = ft_model_f2.cross_validate(train_fold2_df, num_folds=5, num_epochs=10,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-5,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a7bb2da-3bd2-4259-9ab0-aaca72f93af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test BCELoss: 2.44447\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test Accuracy: 0.59\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.74680\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f2.test_model(test_fold2_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf87087d-093a-4300-847b-b1b7984e1aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f3 = generate_model(checkpoints_path, batch_size=32, dropout=0.5)\n",
    "f3_res = ft_model_f3.cross_validate(train_fold3_df, num_folds=5, num_epochs=10,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-5,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8174af-0dd4-4751-9f33-9adfc86f9ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test BCELoss: 1.72908\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test Accuracy: 0.61\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.77388\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f3.test_model(test_fold3_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abd1775-1770-4e70-b8b6-c04a9f516b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f4 = generate_model(checkpoints_path, batch_size=32, dropout=0.5)\n",
    "f4_res = ft_model_f4.cross_validate(train_fold4_df, num_folds=5, num_epochs=10,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-5,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d377e2-c962-4631-a835-78ced5eadf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test BCELoss: 1.07892\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test Accuracy: 0.74\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test AUC: 0.88776\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model_f4.test_model(test_fold4_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dff27c-4555-4a7a-95bf-f90f5df61732",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f5 = generate_model(checkpoints_path, batch_size=32, dropout=0.5)\n",
    "f5_res = ft_model_f5.cross_validate(train_fold5_df, num_folds=5, num_epochs=10,\n",
    "                     batch_size=32, learning_rate=0.0001, weight_decay=1e-5,\n",
    "                     shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba86247-1899-498b-8f41-0dfaefdd96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_f5.test_model(test_fold5_df,\n",
    "                         criterion= nn.BCELoss() ,batch_size=32,\n",
    "                         shuffle=True, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# DLiP Web Scraping Project

![beautifulsoup_logo_r](https://github.com/Gavision97/DeepLearningResearchStarship/assets/150701079/24628e07-f94d-420e-8dd0-e2c09bb83035)
![selenium_logo_r](https://github.com/Gavision97/DeepLearningResearchStarship/assets/150701079/249c53f2-c97d-4d25-a136-b9309296dd6b)


## Overview

This project focuses on web scraping techniques using Python libraries such as Selenium and BeautifulSoup to extract and manipulate data from the DLiP (Database of Chemical Library for Protein-Protein Interaction) website.

## Project Objective

The primary goal is to automate the extraction of Protein-Protein Interaction (PPI) tables from the DLiP website. The extracted data will be prepared and structured for further use in deep learning research.

## Tools and Technologies

- **Python**: Core programming language for implementing web scraping logic.
- **Selenium**: Automates web browsers to interact with dynamic content.
- **BeautifulSoup**: Python library for parsing HTML and XML, facilitating data extraction from web pages.

## Key Steps

1. **Initialization**: Set up the Selenium webdriver for navigating the DLiP website.
   
2. **Data Extraction**: Use Selenium to interact with the website and extract PPI tables.

3. **Data Manipulation**: Utilize BeautifulSoup to parse HTML content and structure the data.

4. **DataFrame Creation**: Organize the data into Pandas DataFrames for easy manipulation.

5. **Automation and Iteration**: Implement a loop to navigate through multiple pages, extracting data from each.

6. **CSV Export**: Save the final structured data into a CSV file for further analysis.

## Output

The project will generate a CSV file containing the extracted and structured data from the DLiP website. This CSV file serves as a valuable resource for deep learning research involving chemical libraries and protein-protein interactions.

Feel free to explore and modify the project code to suit your specific requirements or integrate it into your deep learning workflows.

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f2445d6-5735-43be-ac05-9d2358636a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, RobertaModel, RobertaConfig, AdamW, get_linear_schedule_with_warmup , BertModel\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff6127ef-3999-4acd-9c25-c7ff38d6565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>Entry</th>\n",
       "      <th>Reviewed</th>\n",
       "      <th>Entry Name</th>\n",
       "      <th>Protein names</th>\n",
       "      <th>Gene Names</th>\n",
       "      <th>Organism</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q15788</td>\n",
       "      <td>Q15788</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>NCOA1_HUMAN</td>\n",
       "      <td>Nuclear receptor coactivator 1 (NCoA-1) (EC 2....</td>\n",
       "      <td>NCOA1 BHLHE74 SRC1</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>1441</td>\n",
       "      <td>MSGLGDSSSDPANPDSHKRKGSPCDTLASSTEKRRREQENKYLEEL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O14867</td>\n",
       "      <td>O14867</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>BACH1_HUMAN</td>\n",
       "      <td>Transcription regulator protein BACH1 (BTB and...</td>\n",
       "      <td>BACH1</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>736</td>\n",
       "      <td>MSLSENSVFAYESSVHSTNVLLSLNDQRKKDVLCDVTIFVEGQRFR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q13797</td>\n",
       "      <td>Q13797</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ITA9_HUMAN</td>\n",
       "      <td>Integrin alpha-9 (Integrin alpha-RLC)</td>\n",
       "      <td>ITGA9</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>1035</td>\n",
       "      <td>MGGPAAPRGAGRLRALLLALVVAGIPAGAYNLDPQRPVHFQGPADS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q6PL18</td>\n",
       "      <td>Q6PL18</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ATAD2_HUMAN</td>\n",
       "      <td>ATPase family AAA domain-containing protein 2 ...</td>\n",
       "      <td>ATAD2 L16 PRO2000</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>1390</td>\n",
       "      <td>MVVLRSSLELHNHSAASATGSLDLSSDFLSLEHIGRRRLRSAGAAQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O00512</td>\n",
       "      <td>O00512</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>BCL9_HUMAN</td>\n",
       "      <td>B-cell CLL/lymphoma 9 protein (B-cell lymphoma...</td>\n",
       "      <td>BCL9</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>1426</td>\n",
       "      <td>MHSSNPKVRSSPSGNTQSSPKSKQEVMVRPPTVMSPSGNPQLDSKF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>O14786</td>\n",
       "      <td>O14786</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>NRP1_HUMAN</td>\n",
       "      <td>Neuropilin-1 (Vascular endothelial cell growth...</td>\n",
       "      <td>NRP1 NRP VEGF165R</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>923</td>\n",
       "      <td>MERGLPLLCAVLALVLAPAGAFRNDKCGDTIKIESPGYLTSPGYPH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Q13501</td>\n",
       "      <td>Q13501</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>SQSTM_HUMAN</td>\n",
       "      <td>Sequestosome-1 (EBI3-associated protein of 60 ...</td>\n",
       "      <td>SQSTM1 ORCA OSIL</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>440</td>\n",
       "      <td>MASLTVKAYLLGKEDAAREIRRFSFCCSPEPEAEAEAAAGPGPCER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Q92843</td>\n",
       "      <td>Q92843</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>B2CL2_HUMAN</td>\n",
       "      <td>Bcl-2-like protein 2 (Bcl2-L-2) (Apoptosis reg...</td>\n",
       "      <td>BCL2L2 BCLW KIAA0271</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>193</td>\n",
       "      <td>MATPASAPDTRALVADFVGYKLRQKGYVCGAGPGEGPAADPLHQAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>P51587</td>\n",
       "      <td>P51587</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>BRCA2_HUMAN</td>\n",
       "      <td>Breast cancer type 2 susceptibility protein (F...</td>\n",
       "      <td>BRCA2 FACD FANCD1</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>3418</td>\n",
       "      <td>MPIGSKERPTFFEIFKTRCNKADLGPISLNWFEELSSEAPPYNSEP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>P15884</td>\n",
       "      <td>P15884</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ITF2_HUMAN</td>\n",
       "      <td>Transcription factor 4 (TCF-4) (Class B basic ...</td>\n",
       "      <td>TCF4 BHLHB19 ITF2 SEF2</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>667</td>\n",
       "      <td>MHHQQRMAALGTDKELSDLLDFSAMFSPPVSSGKNGPTSLASGHFT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       From   Entry  Reviewed   Entry Name  \\\n",
       "0    Q15788  Q15788  reviewed  NCOA1_HUMAN   \n",
       "1    O14867  O14867  reviewed  BACH1_HUMAN   \n",
       "2    Q13797  Q13797  reviewed   ITA9_HUMAN   \n",
       "3    Q6PL18  Q6PL18  reviewed  ATAD2_HUMAN   \n",
       "4    O00512  O00512  reviewed   BCL9_HUMAN   \n",
       "..      ...     ...       ...          ...   \n",
       "291  O14786  O14786  reviewed   NRP1_HUMAN   \n",
       "292  Q13501  Q13501  reviewed  SQSTM_HUMAN   \n",
       "293  Q92843  Q92843  reviewed  B2CL2_HUMAN   \n",
       "294  P51587  P51587  reviewed  BRCA2_HUMAN   \n",
       "295  P15884  P15884  reviewed   ITF2_HUMAN   \n",
       "\n",
       "                                         Protein names  \\\n",
       "0    Nuclear receptor coactivator 1 (NCoA-1) (EC 2....   \n",
       "1    Transcription regulator protein BACH1 (BTB and...   \n",
       "2                Integrin alpha-9 (Integrin alpha-RLC)   \n",
       "3    ATPase family AAA domain-containing protein 2 ...   \n",
       "4    B-cell CLL/lymphoma 9 protein (B-cell lymphoma...   \n",
       "..                                                 ...   \n",
       "291  Neuropilin-1 (Vascular endothelial cell growth...   \n",
       "292  Sequestosome-1 (EBI3-associated protein of 60 ...   \n",
       "293  Bcl-2-like protein 2 (Bcl2-L-2) (Apoptosis reg...   \n",
       "294  Breast cancer type 2 susceptibility protein (F...   \n",
       "295  Transcription factor 4 (TCF-4) (Class B basic ...   \n",
       "\n",
       "                 Gene Names              Organism  Length  \\\n",
       "0        NCOA1 BHLHE74 SRC1  Homo sapiens (Human)    1441   \n",
       "1                     BACH1  Homo sapiens (Human)     736   \n",
       "2                     ITGA9  Homo sapiens (Human)    1035   \n",
       "3         ATAD2 L16 PRO2000  Homo sapiens (Human)    1390   \n",
       "4                      BCL9  Homo sapiens (Human)    1426   \n",
       "..                      ...                   ...     ...   \n",
       "291       NRP1 NRP VEGF165R  Homo sapiens (Human)     923   \n",
       "292        SQSTM1 ORCA OSIL  Homo sapiens (Human)     440   \n",
       "293    BCL2L2 BCLW KIAA0271  Homo sapiens (Human)     193   \n",
       "294       BRCA2 FACD FANCD1  Homo sapiens (Human)    3418   \n",
       "295  TCF4 BHLHB19 ITF2 SEF2  Homo sapiens (Human)     667   \n",
       "\n",
       "                                              Sequence  \n",
       "0    MSGLGDSSSDPANPDSHKRKGSPCDTLASSTEKRRREQENKYLEEL...  \n",
       "1    MSLSENSVFAYESSVHSTNVLLSLNDQRKKDVLCDVTIFVEGQRFR...  \n",
       "2    MGGPAAPRGAGRLRALLLALVVAGIPAGAYNLDPQRPVHFQGPADS...  \n",
       "3    MVVLRSSLELHNHSAASATGSLDLSSDFLSLEHIGRRRLRSAGAAQ...  \n",
       "4    MHSSNPKVRSSPSGNTQSSPKSKQEVMVRPPTVMSPSGNPQLDSKF...  \n",
       "..                                                 ...  \n",
       "291  MERGLPLLCAVLALVLAPAGAFRNDKCGDTIKIESPGYLTSPGYPH...  \n",
       "292  MASLTVKAYLLGKEDAAREIRRFSFCCSPEPEAEAEAAAGPGPCER...  \n",
       "293  MATPASAPDTRALVADFVGYKLRQKGYVCGAGPGEGPAADPLHQAM...  \n",
       "294  MPIGSKERPTFFEIFKTRCNKADLGPISLNWFEELSSEAPPYNSEP...  \n",
       "295  MHHQQRMAALGTDKELSDLLDFSAMFSPPVSSGKNGPTSLASGHFT...  \n",
       "\n",
       "[296 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"/sise/home/adamu/thesis_new/datasets/final_dataset_2_0.75.csv\")\n",
    "esm_features = pd.read_csv(\"/sise/home/adamu/thesis_new/feature_extraction/outputs/esm_features.csv\")\n",
    "uniprot_mapping = pd.read_csv(\"/sise/home/adamu/thesis_new/feature_extraction/data/idmapping_2024_05_09.tsv\",  delimiter = \"\\t\")\n",
    "uniprot_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "703efed4-5f2c-49fb-a300-d9040d0455d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_uniprot_ids(dataset, mapping_df):\n",
    "    # Create a dictionary from the mapping dataframe\n",
    "    mapping_dict = mapping_df.set_index('From')['Entry'].to_dict()\n",
    "\n",
    "    # Map the uniprot_id1 and uniprot_id2 columns to their respective Entry values\n",
    "    dataset['uniprot_id1'] = dataset['uniprot_id1'].map(mapping_dict)\n",
    "    dataset['uniprot_id2'] = dataset['uniprot_id2'].map(mapping_dict)\n",
    "    return dataset.drop_duplicates()\n",
    "    \n",
    "def merge_datasets(dataset, features_df):\n",
    "    # Merge features for uniprot_id1\n",
    "    dataset = dataset.merge(features_df, how='left', left_on='uniprot_id1', right_on='UniProt_ID', suffixes=('', '_id1'))\n",
    "    dataset = dataset.drop(columns=['UniProt_ID'])\n",
    "    \n",
    "    # Merge features for uniprot_id2\n",
    "    features_df_renamed = features_df.add_suffix('_id2')\n",
    "    features_df_renamed = features_df_renamed.rename(columns={'UniProt_ID_id2': 'UniProt_ID'})\n",
    "    dataset = dataset.merge(features_df_renamed, how='left', left_on='uniprot_id2', right_on='UniProt_ID', suffixes=('', '_id2'))\n",
    "    dataset = dataset.drop(columns=['UniProt_ID', 'uniprot_id1', 'uniprot_id2'])\n",
    "    \n",
    "    return dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e631de45-fe09-47e1-8871-fba65ecad2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>label</th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_1270_id2</th>\n",
       "      <th>Feature_1271_id2</th>\n",
       "      <th>Feature_1272_id2</th>\n",
       "      <th>Feature_1273_id2</th>\n",
       "      <th>Feature_1274_id2</th>\n",
       "      <th>Feature_1275_id2</th>\n",
       "      <th>Feature_1276_id2</th>\n",
       "      <th>Feature_1277_id2</th>\n",
       "      <th>Feature_1278_id2</th>\n",
       "      <th>Feature_1279_id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OC(=O)c1nc(sc1-c1ccc(cc1)-c1ccccc1)-c1ccc2CCCN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>-0.091496</td>\n",
       "      <td>-0.021745</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>-0.045568</td>\n",
       "      <td>-0.076223</td>\n",
       "      <td>0.067172</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046108</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>-0.160452</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>-0.045173</td>\n",
       "      <td>-0.135907</td>\n",
       "      <td>0.036617</td>\n",
       "      <td>-0.136259</td>\n",
       "      <td>-0.023708</td>\n",
       "      <td>0.164988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN1C(=O)N(c2cc(Cl)cc(Cl)c2)C(=O)[C@]12CN(c1nc3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018931</td>\n",
       "      <td>-0.050427</td>\n",
       "      <td>-0.001708</td>\n",
       "      <td>0.052669</td>\n",
       "      <td>-0.015171</td>\n",
       "      <td>-0.051038</td>\n",
       "      <td>0.085986</td>\n",
       "      <td>-0.013006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095369</td>\n",
       "      <td>-0.000298</td>\n",
       "      <td>-0.187148</td>\n",
       "      <td>0.049039</td>\n",
       "      <td>-0.007977</td>\n",
       "      <td>-0.004218</td>\n",
       "      <td>-0.013003</td>\n",
       "      <td>-0.156473</td>\n",
       "      <td>0.049008</td>\n",
       "      <td>0.133108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)NS(=O)(=O)c1ccc(OCC(=O)N2CCOCC2)cc1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.020703</td>\n",
       "      <td>-0.077155</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>0.065730</td>\n",
       "      <td>-0.108772</td>\n",
       "      <td>-0.025299</td>\n",
       "      <td>0.091760</td>\n",
       "      <td>-0.013818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052764</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>-0.032889</td>\n",
       "      <td>0.013346</td>\n",
       "      <td>-0.002336</td>\n",
       "      <td>-0.061765</td>\n",
       "      <td>0.122240</td>\n",
       "      <td>-0.107535</td>\n",
       "      <td>-0.056424</td>\n",
       "      <td>0.064282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(=O)N1CCN(C(=O)/C=C/c2ccc(Sc3ccccc3C(N)=O)c(...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022582</td>\n",
       "      <td>-0.052505</td>\n",
       "      <td>-0.042596</td>\n",
       "      <td>0.089144</td>\n",
       "      <td>-0.089632</td>\n",
       "      <td>-0.131044</td>\n",
       "      <td>0.148719</td>\n",
       "      <td>0.032024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013739</td>\n",
       "      <td>0.025413</td>\n",
       "      <td>-0.184884</td>\n",
       "      <td>0.035220</td>\n",
       "      <td>-0.037794</td>\n",
       "      <td>-0.026719</td>\n",
       "      <td>0.093608</td>\n",
       "      <td>-0.122195</td>\n",
       "      <td>-0.045078</td>\n",
       "      <td>0.117260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(C)C1=C(SC2=N[C@](C)([C@H](N12)c1ccc(Cl)cc1)...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033985</td>\n",
       "      <td>-0.059724</td>\n",
       "      <td>-0.006932</td>\n",
       "      <td>0.144283</td>\n",
       "      <td>-0.005031</td>\n",
       "      <td>-0.037092</td>\n",
       "      <td>0.083921</td>\n",
       "      <td>0.026034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084858</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>-0.058713</td>\n",
       "      <td>0.010643</td>\n",
       "      <td>0.022048</td>\n",
       "      <td>-0.019426</td>\n",
       "      <td>0.027595</td>\n",
       "      <td>-0.099573</td>\n",
       "      <td>0.011354</td>\n",
       "      <td>0.013198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109226</th>\n",
       "      <td>Clc1cc(OCCN2CCOCC2)ccc1Nc1nc2c(-c3nnc[nH]3)ccc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>-0.091496</td>\n",
       "      <td>-0.021745</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>-0.045568</td>\n",
       "      <td>-0.076223</td>\n",
       "      <td>0.067172</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046108</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>-0.160452</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>-0.045173</td>\n",
       "      <td>-0.135907</td>\n",
       "      <td>0.036617</td>\n",
       "      <td>-0.136259</td>\n",
       "      <td>-0.023708</td>\n",
       "      <td>0.164988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109227</th>\n",
       "      <td>COC(=O)c1cc(O)cc(OC)c1Oc1cc(C)cc(O)c1C(=O)O</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.038923</td>\n",
       "      <td>-0.071458</td>\n",
       "      <td>0.011513</td>\n",
       "      <td>0.078479</td>\n",
       "      <td>-0.190378</td>\n",
       "      <td>0.070974</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.020999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095667</td>\n",
       "      <td>0.027029</td>\n",
       "      <td>-0.136574</td>\n",
       "      <td>-0.025870</td>\n",
       "      <td>0.009829</td>\n",
       "      <td>-0.081369</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>-0.073539</td>\n",
       "      <td>0.061196</td>\n",
       "      <td>0.029591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109228</th>\n",
       "      <td>CCCC1=CN(C[C@H](NC(=O)OCc2ccccc2)C(=O)O)C(=O)N...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>-0.091496</td>\n",
       "      <td>-0.021745</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>-0.045568</td>\n",
       "      <td>-0.076223</td>\n",
       "      <td>0.067172</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046108</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>-0.160452</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>-0.045173</td>\n",
       "      <td>-0.135907</td>\n",
       "      <td>0.036617</td>\n",
       "      <td>-0.136259</td>\n",
       "      <td>-0.023708</td>\n",
       "      <td>0.164988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109229</th>\n",
       "      <td>O=C(CSc1nc2ccccc2c(=O)n1Cc1ccc2c(c1)OCO2)NCc1c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016134</td>\n",
       "      <td>-0.060721</td>\n",
       "      <td>-0.051823</td>\n",
       "      <td>0.028336</td>\n",
       "      <td>-0.062652</td>\n",
       "      <td>-0.053298</td>\n",
       "      <td>0.085150</td>\n",
       "      <td>-0.030032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046108</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>-0.160452</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>-0.045173</td>\n",
       "      <td>-0.135907</td>\n",
       "      <td>0.036617</td>\n",
       "      <td>-0.136259</td>\n",
       "      <td>-0.023708</td>\n",
       "      <td>0.164988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109230</th>\n",
       "      <td>Cn1c(Cc2nn(C)c(=O)c3ccccc23)nnc1SCCCCCCCCCCC(=...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029493</td>\n",
       "      <td>-0.003122</td>\n",
       "      <td>0.027661</td>\n",
       "      <td>0.179610</td>\n",
       "      <td>-0.050393</td>\n",
       "      <td>-0.100577</td>\n",
       "      <td>-0.030334</td>\n",
       "      <td>0.141787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005198</td>\n",
       "      <td>-0.003757</td>\n",
       "      <td>-0.317323</td>\n",
       "      <td>0.023060</td>\n",
       "      <td>-0.028668</td>\n",
       "      <td>-0.003731</td>\n",
       "      <td>-0.015514</td>\n",
       "      <td>-0.134455</td>\n",
       "      <td>0.080713</td>\n",
       "      <td>0.014665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109231 rows × 2562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   smiles  label  Feature_0  \\\n",
       "0       OC(=O)c1nc(sc1-c1ccc(cc1)-c1ccccc1)-c1ccc2CCCN...      0   0.033387   \n",
       "1       CN1C(=O)N(c2cc(Cl)cc(Cl)c2)C(=O)[C@]12CN(c1nc3...      0   0.018931   \n",
       "2                CC(C)NS(=O)(=O)c1ccc(OCC(=O)N2CCOCC2)cc1      0  -0.020703   \n",
       "3       CC(=O)N1CCN(C(=O)/C=C/c2ccc(Sc3ccccc3C(N)=O)c(...      1   0.022582   \n",
       "4       CC(C)C1=C(SC2=N[C@](C)([C@H](N12)c1ccc(Cl)cc1)...      1   0.033985   \n",
       "...                                                   ...    ...        ...   \n",
       "109226  Clc1cc(OCCN2CCOCC2)ccc1Nc1nc2c(-c3nnc[nH]3)ccc...      0   0.033387   \n",
       "109227        COC(=O)c1cc(O)cc(OC)c1Oc1cc(C)cc(O)c1C(=O)O      0  -0.038923   \n",
       "109228  CCCC1=CN(C[C@H](NC(=O)OCc2ccccc2)C(=O)O)C(=O)N...      0   0.033387   \n",
       "109229  O=C(CSc1nc2ccccc2c(=O)n1Cc1ccc2c(c1)OCO2)NCc1c...      1   0.016134   \n",
       "109230  Cn1c(Cc2nn(C)c(=O)c3ccccc23)nnc1SCCCCCCCCCCC(=...      1   0.029493   \n",
       "\n",
       "        Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0       -0.091496  -0.021745   0.011464  -0.045568  -0.076223   0.067172   \n",
       "1       -0.050427  -0.001708   0.052669  -0.015171  -0.051038   0.085986   \n",
       "2       -0.077155  -0.054688   0.065730  -0.108772  -0.025299   0.091760   \n",
       "3       -0.052505  -0.042596   0.089144  -0.089632  -0.131044   0.148719   \n",
       "4       -0.059724  -0.006932   0.144283  -0.005031  -0.037092   0.083921   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "109226  -0.091496  -0.021745   0.011464  -0.045568  -0.076223   0.067172   \n",
       "109227  -0.071458   0.011513   0.078479  -0.190378   0.070974   0.128713   \n",
       "109228  -0.091496  -0.021745   0.011464  -0.045568  -0.076223   0.067172   \n",
       "109229  -0.060721  -0.051823   0.028336  -0.062652  -0.053298   0.085150   \n",
       "109230  -0.003122   0.027661   0.179610  -0.050393  -0.100577  -0.030334   \n",
       "\n",
       "        Feature_7  ...  Feature_1270_id2  Feature_1271_id2  Feature_1272_id2  \\\n",
       "0        0.002492  ...         -0.046108          0.018945         -0.160452   \n",
       "1       -0.013006  ...          0.095369         -0.000298         -0.187148   \n",
       "2       -0.013818  ...          0.052764          0.007230         -0.032889   \n",
       "3        0.032024  ...          0.013739          0.025413         -0.184884   \n",
       "4        0.026034  ...          0.084858          0.003144         -0.058713   \n",
       "...           ...  ...               ...               ...               ...   \n",
       "109226   0.002492  ...         -0.046108          0.018945         -0.160452   \n",
       "109227   0.020999  ...          0.095667          0.027029         -0.136574   \n",
       "109228   0.002492  ...         -0.046108          0.018945         -0.160452   \n",
       "109229  -0.030032  ...         -0.046108          0.018945         -0.160452   \n",
       "109230   0.141787  ...         -0.005198         -0.003757         -0.317323   \n",
       "\n",
       "        Feature_1273_id2  Feature_1274_id2  Feature_1275_id2  \\\n",
       "0               0.058708         -0.045173         -0.135907   \n",
       "1               0.049039         -0.007977         -0.004218   \n",
       "2               0.013346         -0.002336         -0.061765   \n",
       "3               0.035220         -0.037794         -0.026719   \n",
       "4               0.010643          0.022048         -0.019426   \n",
       "...                  ...               ...               ...   \n",
       "109226          0.058708         -0.045173         -0.135907   \n",
       "109227         -0.025870          0.009829         -0.081369   \n",
       "109228          0.058708         -0.045173         -0.135907   \n",
       "109229          0.058708         -0.045173         -0.135907   \n",
       "109230          0.023060         -0.028668         -0.003731   \n",
       "\n",
       "        Feature_1276_id2  Feature_1277_id2  Feature_1278_id2  Feature_1279_id2  \n",
       "0               0.036617         -0.136259         -0.023708          0.164988  \n",
       "1              -0.013003         -0.156473          0.049008          0.133108  \n",
       "2               0.122240         -0.107535         -0.056424          0.064282  \n",
       "3               0.093608         -0.122195         -0.045078          0.117260  \n",
       "4               0.027595         -0.099573          0.011354          0.013198  \n",
       "...                  ...               ...               ...               ...  \n",
       "109226          0.036617         -0.136259         -0.023708          0.164988  \n",
       "109227          0.001253         -0.073539          0.061196          0.029591  \n",
       "109228          0.036617         -0.136259         -0.023708          0.164988  \n",
       "109229          0.036617         -0.136259         -0.023708          0.164988  \n",
       "109230         -0.015514         -0.134455          0.080713          0.014665  \n",
       "\n",
       "[109231 rows x 2562 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = convert_uniprot_ids(dataset, uniprot_mapping)\n",
    "dataset = merge_datasets(dataset, esm_features)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e15d7651-6ff4-403b-a7b3-f65ad5e197e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>label</th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_1270_id2</th>\n",
       "      <th>Feature_1271_id2</th>\n",
       "      <th>Feature_1272_id2</th>\n",
       "      <th>Feature_1273_id2</th>\n",
       "      <th>Feature_1274_id2</th>\n",
       "      <th>Feature_1275_id2</th>\n",
       "      <th>Feature_1276_id2</th>\n",
       "      <th>Feature_1277_id2</th>\n",
       "      <th>Feature_1278_id2</th>\n",
       "      <th>Feature_1279_id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 2562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [smiles, label, Feature_0, Feature_1, Feature_2, Feature_3, Feature_4, Feature_5, Feature_6, Feature_7, Feature_8, Feature_9, Feature_10, Feature_11, Feature_12, Feature_13, Feature_14, Feature_15, Feature_16, Feature_17, Feature_18, Feature_19, Feature_20, Feature_21, Feature_22, Feature_23, Feature_24, Feature_25, Feature_26, Feature_27, Feature_28, Feature_29, Feature_30, Feature_31, Feature_32, Feature_33, Feature_34, Feature_35, Feature_36, Feature_37, Feature_38, Feature_39, Feature_40, Feature_41, Feature_42, Feature_43, Feature_44, Feature_45, Feature_46, Feature_47, Feature_48, Feature_49, Feature_50, Feature_51, Feature_52, Feature_53, Feature_54, Feature_55, Feature_56, Feature_57, Feature_58, Feature_59, Feature_60, Feature_61, Feature_62, Feature_63, Feature_64, Feature_65, Feature_66, Feature_67, Feature_68, Feature_69, Feature_70, Feature_71, Feature_72, Feature_73, Feature_74, Feature_75, Feature_76, Feature_77, Feature_78, Feature_79, Feature_80, Feature_81, Feature_82, Feature_83, Feature_84, Feature_85, Feature_86, Feature_87, Feature_88, Feature_89, Feature_90, Feature_91, Feature_92, Feature_93, Feature_94, Feature_95, Feature_96, Feature_97, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 2562 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.Feature_0.isna() | dataset.Feature_0_id2.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "08b2b0c3-9a0e-49ad-9db6-21c6b56fd7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "dataset.iloc[:, 2:] = dataset.iloc[:, 2:].astype(float)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# Extract SMILES strings, PPI features, and labels\n",
    "smiles_list = dataset['smiles'].tolist()\n",
    "ppi_features = dataset.iloc[:, 2:].values  # Excluding SMILES and label columns\n",
    "labels = dataset['label'].values\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"DeepChem/ChemBERTa-77M-MTR\")\n",
    "encoded_smiles = tokenizer(smiles_list, truncation=True, padding=True, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edc03143-7c82-472f-9e8c-d101f22bd942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encoded_smiles, ppi_features, labels):\n",
    "        self.encoded_smiles = encoded_smiles\n",
    "        self.ppi_features = torch.tensor(ppi_features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            \"input_ids\": self.encoded_smiles[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encoded_smiles[\"attention_mask\"][idx],\n",
    "            \"ppi_features\": self.ppi_features[idx],\n",
    "            \"labels\": self.labels[idx]\n",
    "        }\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b26e266-2b12-438f-96f2-77a0d935a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "train_data, temp_data, train_labels, temp_labels = train_test_split(dataset, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "valid_data, test_data, valid_labels, test_labels = train_test_split(temp_data, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels)\n",
    "\n",
    "# Convert these splits into their respective Datasets and DataLoaders\n",
    "train_dataset = CustomDataset(tokenizer(train_data['smiles'].tolist(), truncation=True, padding=True, return_tensors=\"pt\"), train_data.iloc[:, 2:].values, train_labels)\n",
    "valid_dataset = CustomDataset(tokenizer(valid_data['smiles'].tolist(), truncation=True, padding=True, return_tensors=\"pt\"), valid_data.iloc[:, 2:].values, valid_labels)\n",
    "test_dataset = CustomDataset(tokenizer(test_data['smiles'].tolist(), truncation=True, padding=True, return_tensors=\"pt\"), test_data.iloc[:, 2:].values, test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7eeed68-550b-4e69-813b-7b27172eff8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_1270_id2</th>\n",
       "      <th>Feature_1271_id2</th>\n",
       "      <th>Feature_1272_id2</th>\n",
       "      <th>Feature_1273_id2</th>\n",
       "      <th>Feature_1274_id2</th>\n",
       "      <th>Feature_1275_id2</th>\n",
       "      <th>Feature_1276_id2</th>\n",
       "      <th>Feature_1277_id2</th>\n",
       "      <th>Feature_1278_id2</th>\n",
       "      <th>Feature_1279_id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63826</th>\n",
       "      <td>-0.009516</td>\n",
       "      <td>-0.048620</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.037495</td>\n",
       "      <td>0.089705</td>\n",
       "      <td>-0.022223</td>\n",
       "      <td>0.022028</td>\n",
       "      <td>0.152187</td>\n",
       "      <td>0.045285</td>\n",
       "      <td>0.051748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012767</td>\n",
       "      <td>-0.027525</td>\n",
       "      <td>-0.085463</td>\n",
       "      <td>0.038302</td>\n",
       "      <td>0.034502</td>\n",
       "      <td>-0.081834</td>\n",
       "      <td>-0.010867</td>\n",
       "      <td>-0.085387</td>\n",
       "      <td>0.033624</td>\n",
       "      <td>0.077056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98240</th>\n",
       "      <td>-0.020703</td>\n",
       "      <td>-0.077155</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>0.065730</td>\n",
       "      <td>-0.108772</td>\n",
       "      <td>-0.025299</td>\n",
       "      <td>0.091760</td>\n",
       "      <td>-0.013818</td>\n",
       "      <td>-0.079494</td>\n",
       "      <td>0.198468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035412</td>\n",
       "      <td>0.052223</td>\n",
       "      <td>-0.199088</td>\n",
       "      <td>0.039508</td>\n",
       "      <td>-0.027858</td>\n",
       "      <td>-0.104056</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>-0.095414</td>\n",
       "      <td>0.010231</td>\n",
       "      <td>0.057766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74598</th>\n",
       "      <td>-0.005542</td>\n",
       "      <td>-0.096082</td>\n",
       "      <td>-0.049218</td>\n",
       "      <td>-0.004587</td>\n",
       "      <td>0.096639</td>\n",
       "      <td>-0.117399</td>\n",
       "      <td>0.065587</td>\n",
       "      <td>0.079753</td>\n",
       "      <td>-0.064333</td>\n",
       "      <td>0.058297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027155</td>\n",
       "      <td>-0.031982</td>\n",
       "      <td>-0.049737</td>\n",
       "      <td>0.152361</td>\n",
       "      <td>0.032702</td>\n",
       "      <td>-0.069526</td>\n",
       "      <td>0.100826</td>\n",
       "      <td>0.034708</td>\n",
       "      <td>-0.079781</td>\n",
       "      <td>0.043650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102131</th>\n",
       "      <td>0.058166</td>\n",
       "      <td>-0.144322</td>\n",
       "      <td>-0.046411</td>\n",
       "      <td>0.098785</td>\n",
       "      <td>-0.164210</td>\n",
       "      <td>-0.044439</td>\n",
       "      <td>0.309844</td>\n",
       "      <td>-0.310033</td>\n",
       "      <td>-0.193687</td>\n",
       "      <td>0.088806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153227</td>\n",
       "      <td>0.024963</td>\n",
       "      <td>-0.114406</td>\n",
       "      <td>-0.013927</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>-0.051427</td>\n",
       "      <td>0.034106</td>\n",
       "      <td>-0.097461</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>-0.044699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82490</th>\n",
       "      <td>-0.027515</td>\n",
       "      <td>-0.093644</td>\n",
       "      <td>0.023019</td>\n",
       "      <td>0.072452</td>\n",
       "      <td>-0.087972</td>\n",
       "      <td>-0.038408</td>\n",
       "      <td>0.183902</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>-0.036904</td>\n",
       "      <td>0.164225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072114</td>\n",
       "      <td>0.023437</td>\n",
       "      <td>-0.090315</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>-0.108461</td>\n",
       "      <td>0.031974</td>\n",
       "      <td>-0.039432</td>\n",
       "      <td>-0.032934</td>\n",
       "      <td>0.044267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>-0.027515</td>\n",
       "      <td>-0.093644</td>\n",
       "      <td>0.023019</td>\n",
       "      <td>0.072452</td>\n",
       "      <td>-0.087972</td>\n",
       "      <td>-0.038408</td>\n",
       "      <td>0.183902</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>-0.036904</td>\n",
       "      <td>0.164225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072114</td>\n",
       "      <td>0.023437</td>\n",
       "      <td>-0.090315</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>-0.108461</td>\n",
       "      <td>0.031974</td>\n",
       "      <td>-0.039432</td>\n",
       "      <td>-0.032934</td>\n",
       "      <td>0.044267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71060</th>\n",
       "      <td>0.014477</td>\n",
       "      <td>-0.060971</td>\n",
       "      <td>0.028221</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>-0.034841</td>\n",
       "      <td>-0.071785</td>\n",
       "      <td>0.078922</td>\n",
       "      <td>-0.039060</td>\n",
       "      <td>-0.020456</td>\n",
       "      <td>0.097615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017056</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.180716</td>\n",
       "      <td>0.031813</td>\n",
       "      <td>-0.013119</td>\n",
       "      <td>-0.175944</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>-0.079875</td>\n",
       "      <td>-0.004251</td>\n",
       "      <td>0.074700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100504</th>\n",
       "      <td>0.063274</td>\n",
       "      <td>-0.029659</td>\n",
       "      <td>0.015889</td>\n",
       "      <td>0.101089</td>\n",
       "      <td>-0.016113</td>\n",
       "      <td>-0.101207</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.111697</td>\n",
       "      <td>0.024047</td>\n",
       "      <td>0.033692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024946</td>\n",
       "      <td>-0.011196</td>\n",
       "      <td>-0.193725</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.027750</td>\n",
       "      <td>-0.031218</td>\n",
       "      <td>0.054268</td>\n",
       "      <td>-0.062203</td>\n",
       "      <td>-0.028887</td>\n",
       "      <td>0.091523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94930</th>\n",
       "      <td>0.019827</td>\n",
       "      <td>-0.132773</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.141837</td>\n",
       "      <td>-0.097555</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.215369</td>\n",
       "      <td>-0.009062</td>\n",
       "      <td>0.020522</td>\n",
       "      <td>0.144291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055858</td>\n",
       "      <td>0.055593</td>\n",
       "      <td>-0.091637</td>\n",
       "      <td>0.041687</td>\n",
       "      <td>-0.016587</td>\n",
       "      <td>-0.035697</td>\n",
       "      <td>0.025542</td>\n",
       "      <td>-0.037288</td>\n",
       "      <td>0.011203</td>\n",
       "      <td>0.017735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7776</th>\n",
       "      <td>-0.027515</td>\n",
       "      <td>-0.093644</td>\n",
       "      <td>0.023019</td>\n",
       "      <td>0.072452</td>\n",
       "      <td>-0.087972</td>\n",
       "      <td>-0.038408</td>\n",
       "      <td>0.183902</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>-0.036904</td>\n",
       "      <td>0.164225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072114</td>\n",
       "      <td>0.023437</td>\n",
       "      <td>-0.090315</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>-0.108461</td>\n",
       "      <td>0.031974</td>\n",
       "      <td>-0.039432</td>\n",
       "      <td>-0.032934</td>\n",
       "      <td>0.044267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87384 rows × 2560 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
       "63826   -0.009516  -0.048620   0.004722   0.037495   0.089705  -0.022223   \n",
       "98240   -0.020703  -0.077155  -0.054688   0.065730  -0.108772  -0.025299   \n",
       "74598   -0.005542  -0.096082  -0.049218  -0.004587   0.096639  -0.117399   \n",
       "102131   0.058166  -0.144322  -0.046411   0.098785  -0.164210  -0.044439   \n",
       "82490   -0.027515  -0.093644   0.023019   0.072452  -0.087972  -0.038408   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "3348    -0.027515  -0.093644   0.023019   0.072452  -0.087972  -0.038408   \n",
       "71060    0.014477  -0.060971   0.028221   0.096667  -0.034841  -0.071785   \n",
       "100504   0.063274  -0.029659   0.015889   0.101089  -0.016113  -0.101207   \n",
       "94930    0.019827  -0.132773  -0.000028   0.141837  -0.097555   0.025639   \n",
       "7776    -0.027515  -0.093644   0.023019   0.072452  -0.087972  -0.038408   \n",
       "\n",
       "        Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_1270_id2  \\\n",
       "63826    0.022028   0.152187   0.045285   0.051748  ...          0.012767   \n",
       "98240    0.091760  -0.013818  -0.079494   0.198468  ...         -0.035412   \n",
       "74598    0.065587   0.079753  -0.064333   0.058297  ...          0.027155   \n",
       "102131   0.309844  -0.310033  -0.193687   0.088806  ...          0.153227   \n",
       "82490    0.183902   0.003826  -0.036904   0.164225  ...          0.072114   \n",
       "...           ...        ...        ...        ...  ...               ...   \n",
       "3348     0.183902   0.003826  -0.036904   0.164225  ...          0.072114   \n",
       "71060    0.078922  -0.039060  -0.020456   0.097615  ...          0.017056   \n",
       "100504   0.000601   0.111697   0.024047   0.033692  ...          0.024946   \n",
       "94930    0.215369  -0.009062   0.020522   0.144291  ...          0.055858   \n",
       "7776     0.183902   0.003826  -0.036904   0.164225  ...          0.072114   \n",
       "\n",
       "        Feature_1271_id2  Feature_1272_id2  Feature_1273_id2  \\\n",
       "63826          -0.027525         -0.085463          0.038302   \n",
       "98240           0.052223         -0.199088          0.039508   \n",
       "74598          -0.031982         -0.049737          0.152361   \n",
       "102131          0.024963         -0.114406         -0.013927   \n",
       "82490           0.023437         -0.090315          0.004398   \n",
       "...                  ...               ...               ...   \n",
       "3348            0.023437         -0.090315          0.004398   \n",
       "71060          -0.000085         -0.180716          0.031813   \n",
       "100504         -0.011196         -0.193725         -0.000243   \n",
       "94930           0.055593         -0.091637          0.041687   \n",
       "7776            0.023437         -0.090315          0.004398   \n",
       "\n",
       "        Feature_1274_id2  Feature_1275_id2  Feature_1276_id2  \\\n",
       "63826           0.034502         -0.081834         -0.010867   \n",
       "98240          -0.027858         -0.104056          0.072464   \n",
       "74598           0.032702         -0.069526          0.100826   \n",
       "102131          0.006024         -0.051427          0.034106   \n",
       "82490           0.011356         -0.108461          0.031974   \n",
       "...                  ...               ...               ...   \n",
       "3348            0.011356         -0.108461          0.031974   \n",
       "71060          -0.013119         -0.175944         -0.003636   \n",
       "100504         -0.027750         -0.031218          0.054268   \n",
       "94930          -0.016587         -0.035697          0.025542   \n",
       "7776            0.011356         -0.108461          0.031974   \n",
       "\n",
       "        Feature_1277_id2  Feature_1278_id2  Feature_1279_id2  \n",
       "63826          -0.085387          0.033624          0.077056  \n",
       "98240          -0.095414          0.010231          0.057766  \n",
       "74598           0.034708         -0.079781          0.043650  \n",
       "102131         -0.097461          0.034687         -0.044699  \n",
       "82490          -0.039432         -0.032934          0.044267  \n",
       "...                  ...               ...               ...  \n",
       "3348           -0.039432         -0.032934          0.044267  \n",
       "71060          -0.079875         -0.004251          0.074700  \n",
       "100504         -0.062203         -0.028887          0.091523  \n",
       "94930          -0.037288          0.011203          0.017735  \n",
       "7776           -0.039432         -0.032934          0.044267  \n",
       "\n",
       "[87384 rows x 2560 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00eb9dfc-9a0a-4795-b421-c031b7b08892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ChemBERTaWithPPI(nn.Module):\n",
    "    def __init__(self, model_name, ppi_feature_size, hidden_size1=1024, hidden_size2=512, hidden_size3 = 256):\n",
    "        super(ChemBERTaWithPPI, self).__init__()\n",
    "        self.chemberta = BertModel.from_pretrained(model_name)\n",
    "        self.ppi_fc = nn.Linear(ppi_feature_size, hidden_size1)  # Ensure output matches BERT's dimension\n",
    "        self.hidden_layer1 = nn.Linear(1408, hidden_size1)  # First hidden layer\n",
    "        self.hidden_layer2 = nn.Linear(hidden_size1, hidden_size2)  # New added hidden layer\n",
    "        self.hidden_layer3 = nn.Linear(hidden_size2, hidden_size3)  # New added hidden layer\n",
    "        self.classifier = nn.Linear(hidden_size3, 1)  # Adjusted for the output of the second hidden layer\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, ppi_features):\n",
    "        ppi_out = self.ppi_fc(ppi_features)\n",
    "        \n",
    "        # Expand the dimensions of ppi_out to match bert_output[0]\n",
    "        ppi_out = ppi_out.unsqueeze(1).expand(-1, input_ids.size(1), -1)\n",
    "        \n",
    "        bert_output = self.chemberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        integrated_output = torch.cat((bert_output[0], ppi_out), dim=-1)  # Concatenate along the last dimension\n",
    "        \n",
    "        # Average pooling over the sequence length dimension\n",
    "        pooled_output = integrated_output.mean(dim=1)\n",
    "        \n",
    "        # Passing through the first hidden layer with a ReLU activation function\n",
    "        hidden_output1 = F.relu(self.hidden_layer1(pooled_output))\n",
    "        \n",
    "        # Passing through the second hidden layer with a ReLU activation function\n",
    "        hidden_output2 = F.relu(self.hidden_layer2(hidden_output1))\n",
    "\n",
    "        # Passing through the second hidden layer with a ReLU activation function\n",
    "        hidden_output3 = F.relu(self.hidden_layer3(hidden_output2))\n",
    "        \n",
    "        logits = self.classifier(hidden_output3)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a49f58ec-cb82-4b72-a9d3-238cd022dab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'pooler.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have your data loaded in a DataLoader named `dataloader`\n",
    "model_name = \"DeepChem/ChemBERTa-77M-MTR\"\n",
    "model = ChemBERTaWithPPI(model_name, ppi_feature_size=2560).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8252be5-78ed-4db2-9091-9b0065aa59d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25: 100%|██████████| 1366/1366 [04:57<00:00,  4.59it/s, loss=0.689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Validation AUC: 0.6262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: 100%|██████████| 1366/1366 [04:58<00:00,  4.58it/s, loss=0.452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 - Validation AUC: 0.7269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: 100%|██████████| 1366/1366 [04:57<00:00,  4.60it/s, loss=0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 - Validation AUC: 0.7973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: 100%|██████████| 1366/1366 [04:56<00:00,  4.60it/s, loss=0.443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 - Validation AUC: 0.8432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: 100%|██████████| 1366/1366 [04:57<00:00,  4.60it/s, loss=0.43] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 - Validation AUC: 0.8603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: 100%|██████████| 1366/1366 [04:57<00:00,  4.58it/s, loss=0.615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 - Validation AUC: 0.8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25:  10%|▉         | 130/1366 [00:28<04:30,  4.58it/s, loss=0.288]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 25\n",
    "patience = 5\n",
    "best_auc = 0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=True)\n",
    "    for batch in progress_bar:\n",
    "        # Move batch data to the chosen device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        ppi_features = batch[\"ppi_features\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask, ppi_features)\n",
    "        loss = criterion(logits.squeeze(-1), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Optionally, update the progress bar description with the current loss\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            ppi_features = batch[\"ppi_features\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask, ppi_features)\n",
    "            predictions = torch.sigmoid(logits).squeeze(-1)\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Validation AUC: {auc:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        epochs_without_improvement = 0\n",
    "        # Optionally, save the best model\n",
    "        # torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement == patience:\n",
    "            print(\"Early stopping due to no improvement in validation AUC.\")\n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“pytorch_gpu”",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
